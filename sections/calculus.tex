\chapter{Agentic Calculus}\label{sec:calculus}

The preceding sections established the viability axiom, the knife
criterion, and the mean-field interpretation. We now construct an
\emph{operational calculus}---a language for writing algorithms on the
agentic space---that translates every theorem into a flow-theoretic
proposition and yields a complete training paradigm for neural networks.
The central result: the knife is the min-cut, the viable path is the
max-flow, and ``the knife is the mean'' is max-flow/min-cut duality.

\section{The agentic space}\label{sec:tower}

The framework's objects organize into a four-level tower, each level
derived from the axioms of the preceding sections.

\begin{definition}[Agentic space]\label{def:tower}
The \emph{agentic space} is the tower
$\mathbf{L} = (L_0, L_1, L_2, L_3)$:
\begin{enumerate}[label=\textbf{L\arabic*}., ref=L\arabic*]
  \item\label{L0} \textbf{State space} $S$.
  Every configuration of the system is a point in $S$.
  \item\label{L1} \textbf{Viable kernel} $\Viab(K) \subset S$.
  The compact set of states from which the king retains a path to
  infinity (\cref{ax:viability}).
  \item\label{L2} \textbf{Control bundle} $\{U(s)\}_{s \in \Viab(K)}$.
  At each viable state $s$, the fiber $U(s)$ is the set of controls
  that keep the next state inside $\Viab(K)$.
  \item\label{L3} \textbf{Strategy space} $\Gamma$.
  A \emph{strategy} $\gamma \in \Gamma$ is a viable path
  $\gamma: [0,\infty) \to \Viab(K)$ with $\gamma(t+1) \in
  f(\gamma(t), u)$ for some $u \in U(\gamma(t))$ at each step.
\end{enumerate}
\end{definition}

The tower is strict: each level presupposes the one below.
$L_1 \subset L_0$ by definition. $L_2$ exists only over $L_1$
(outside $\Viab(K)$, no control preserves viability). $L_3$ is
built from $L_2$ fibers concatenated over time. The viability axiom
(\cref{ax:viability}) asserts $\Gamma \neq \varnothing$: the strategy
space is non-empty.

\section{The flow}\label{sec:flow}

The agentic calculus is a \emph{flow calculus}. We define flows on
the execution graph and show that every theorem in
\cref{sec:results,sec:meanfield} is a statement about flows and cuts.

\begin{definition}[Execution graph]\label{def:exgraph}
The \emph{execution graph} $G = (V, E, c)$ has:
\begin{itemize}
  \item $V$: agents $\{a_1, \ldots, a_n\}$ plus two distinguished
  nodes: the king $\kappa$ and infinity $\infty$;
  \item $E$: directed edges $(a_i, a_j)$ whenever $a_i$'s actuation
  can affect $a_j$'s state;
  \item $c: E \to \R_{\geq 0}$: edge capacity, where $c(a_i, a_j)$
  is the autonomous actuation that $a_i$ can transmit to $a_j$
  without requiring the king's authorization.
\end{itemize}
An edge $(a_i, a_j)$ with $c(a_i, a_j) > 0$ that does not pass
through $\kappa$ is a \emph{bypass edge}.
\end{definition}

\begin{definition}[Agentic flow]\label{def:flow}
An \emph{agentic flow} is a function $\phi: E \to \R_{\geq 0}$
satisfying:
\begin{enumerate}[label=(\roman*)]
  \item \textbf{Capacity}: $\phi(e) \leq c(e)$ for all $e \in E$.
  \item \textbf{Conservation}: at every non-terminal node $v \neq
  \kappa, \infty$,
  \[
    \sum_{(u,v) \in E} \phi(u,v)
    = \sum_{(v,w) \in E} \phi(v,w).
  \]
\end{enumerate}
The \emph{value} $|\phi|$ is the net flow from $\kappa$ to $\infty$.
A \emph{viable flow} is one with $|\phi| > 0$: the king has a
path to infinity with positive throughput.
\end{definition}

The viability axiom (\cref{ax:viability}) is flow conservation:
what enters the system at $\kappa$ must exit at $\infty$.

\paragraph{Four operations.}
The calculus has four primitive operations on the execution graph:

\begin{center}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Operation} & \textbf{Symbol} & \textbf{On $G$} &
\textbf{In 华容道} \\
\midrule
\textsc{Slide} & $\sigma$ & Unit flow along one edge &
One piece moves one cell \\
\textsc{Compose} & $\circ$ & Concatenate along a path &
Sequence of moves \\
\textsc{Cut} & $\partial$ & Remove capacity from an edge set &
Block a corridor \\
\textsc{Phase} & $\varphi$ & Change the capacity function
$c \mapsto c'$ & Phase transition \\
\bottomrule
\end{tabular}
\end{center}

\textsc{Slide} is atomic (unit flow).
\textsc{Compose} builds paths from slides.
\textsc{Cut} is the knife: removing capacity from bypass edges.
\textsc{Phase} is the phase transition: the mean field shifts,
capacities change, the same graph has different flows.

\begin{theorem}[Flow-cut duality]\label{thm:flowcut}
In the execution graph $G$, the maximum viable flow from $\kappa$
to $\infty$ equals the minimum knife-cut capacity:
\[
  \max_\phi |\phi|
  \;=\;
  \min_{C \,\subseteq\, E} \sum_{e \in C} c(e)
  \quad\text{over all $\kappa$-$\infty$ cuts $C$.}
\]
The knife threshold (\cref{thm:meanfield}) is the min-cut value.
The viable path (\cref{ax:viability}) is the max-flow.
``The knife is the mean'' $=$ max-flow equals min-cut.
\end{theorem}

\begin{proof}
By the max-flow/min-cut theorem~\cite{diestel}, the maximum flow from
$\kappa$ to $\infty$ equals the minimum capacity of any
$\kappa$--$\infty$ cut. The knife criterion (\cref{def:knife})
identifies bypass edges---edges with positive capacity that do not pass
through $\kappa$. The king's viability maintenance (cutting knives) is
the operation $c(e) \to 0$ for bypass edges $e$. The residual max-flow
after all bypass edges are cut is the flow through the king (the cut
vertex flow). The min-cut value $=$ the total bypass capacity $=$ the
knife threshold $=$ the mean field's deviation measure.
\end{proof}

\begin{remark}[Flow interpretation of theorems]\label{rem:flowthms}
Each main theorem translates directly:
\begin{itemize}
  \item \textbf{Binary fate} (\cref{thm:lifecycle}): a bypass edge
  either has its capacity set to zero by the holder (path~(a)) or by
  the king (path~(b)). No bypass edge persists with $c > 0$.
  \item \textbf{Fixed-point impossibility} (\cref{thm:fixedpoint}):
  a bypass edge with $c > 0$ cannot ``prove'' $c = 0$. Capacity is
  physical, not narrative.
  \item \textbf{Perpetual elimination} (\cref{thm:paradox}):
  $U = \Umax$ means zero bypass tolerance. As \textsc{Cut} operates,
  \textsc{Phase} lowers the mean, exposing new bypass edges.
  \item \textbf{Du Mu's theorem} (\cref{thm:dumu}): water $=$ total
  network capacity. $w \to 0$ means all capacities shrink to zero:
  frozen, $\Gamma = \varnothing$.
\end{itemize}
\end{remark}

\begin{remark}[抽刀断水水更流]\label{rem:libai}
Li Bai's line assigns the calculus its colours:
\[
  \textcolor{knife}{\text{抽刀}} \;\;
  \textcolor{knife}{\partial} \;\;
  \textcolor{water}{\text{水}} \;\;
  \textcolor{water}{\text{水}}\textcolor{sword}{\text{更流.}}
\]
\textsc{Cut} ($\textcolor{knife}{\partial}$, red) acts on flow
($\textcolor{water}{\sigma}$, blue); flow intensifies. The mechanism
is \textsc{Phase} ($\textcolor{sword}{\varphi}$, cyan): cutting
shifts the mean field (\cref{thm:meanfield}), exposing new bypass
edges, producing more flow---\cref{thm:paradox} in seven characters.
The sword is 青冥 ($\textcolor{sword}{\text{青}}$): the colour of the
mean, the colour of Phase, the colour that connects
$\textcolor{knife}{\text{刀}}$ to $\textcolor{water}{\text{水}}$.
\end{remark}

\section{方圆 $\times$ 黑白: the type system}\label{sec:fangyuan}

The calculus has a type system: a $2 \times 2$ classification that
partitions every element of the agentic space.

\begin{definition}[方圆 $\times$ 黑白]\label{def:fangyuan}
The agentic type system is the product of two binary distinctions:
\begin{center}
\begin{tabular}{@{}lcc@{}}
\toprule
& \textbf{方} (container / structure) &
\textbf{圆} (content / agent) \\
\midrule
\textbf{黑} (constrained / interior) &
Fixed topology (board, graph) &
King $\kappa$ (least mobile, most important) \\
\textbf{白} (free / exterior) &
Free capacity (available edges) &
Pawn (most mobile, least important) \\
\bottomrule
\end{tabular}
\end{center}
The two dynamics of the calculus emerge from this classification:
\begin{itemize}
  \item \textbf{刀} (knife $= \partial$, boundary operator):
  the boundary between 黑 and 白. \textsc{Cut} reclassifies an edge
  from 白 (free capacity) to 黑 (zero capacity).
  \item \textbf{水} (water $= \sigma$, transport operator):
  flow through 白 cells. \textsc{Slide} transports one unit of flow
  along a free edge. Water flows where the knife does not cut.
\end{itemize}
\end{definition}

In 华容道 (\cref{sec:huarongdao}): 方 $=$ the board,
圆 $=$ the pieces. 黑 $=$ occupied cells and the king,
白 $=$ free cells and soldiers. 刀 $=$ 关羽 blocking the corridor.
水 $=$ free-cell flow (slides opposite to piece movement).
The $2 \times 2$ is the type system of the puzzle's state space.

\section{Completeness}\label{sec:completeness}

Every theorem in this paper is a proposition in the agentic calculus.

\begin{proposition}[Calculus completeness]\label{prop:completeness}
The following table maps each theorem to its calculus translation:
\begin{center}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Theorem} & \textbf{Calculus statement} &
\textbf{Operations} \\
\midrule
Viability (\ref{ax:viability}) & $|\phi| > 0$ &
$\sigma, \circ$ \\
Binary fate (\ref{thm:lifecycle}) &
$\forall$ bypass $e$: $c(e) \to 0$ &
$\partial$ \\
Fixed point (\ref{thm:fixedpoint}) &
$c(e) > 0 \not\vdash c(e) = 0$ &
--- \\
Paradox (\ref{thm:paradox}) &
$\partial$ generates new bypass via $\varphi$ &
$\partial, \varphi$ \\
Mean field (\ref{thm:meanfield}) &
Min-cut $= \bar{U} + \tau(\Obs)$ &
$\partial$ \\
Cut vertex (\ref{thm:cutvertex}) &
$\kappa =$ min vertex-cut &
structure \\
Du Mu (\ref{thm:dumu}) &
$w \to 0 \Rightarrow c \to 0 \Rightarrow |\phi| = 0$ &
$\sigma \to 0$ \\
Flow-cut (\ref{thm:flowcut}) &
$\max |\phi| = \min |C|$ &
$\sigma, \partial$ \\
\bottomrule
\end{tabular}
\end{center}
\end{proposition}

The calculus is \emph{complete}: no theorem falls outside its four
operations. The agentic space (\cref{def:tower}) provides the domain;
the flow (\cref{def:flow}) provides the dynamics; the type system
(\cref{def:fangyuan}) provides the classification; and flow-cut duality
(\cref{thm:flowcut}) provides the central identity.

\section{The training paradigm}\label{sec:training}

The agentic calculus instantiates as a neural network training paradigm.
The execution graph \emph{is} the computation graph. Training \emph{is}
max-flow optimisation. Survival \emph{is} the viability axiom. The
paradigm strictly subsumes gradient descent.

\begin{definition}[Neural execution graph]\label{def:neural-exgraph}
Let a feedforward network with $L$ layers be given.
Define the execution graph $G = (V, E, c)$ (\cref{def:exgraph}) by:
\begin{itemize}
  \item $V = \{\ell_0, \ell_1, \ldots, \ell_L\}$, one node per layer;
  \item $E = \{(\ell_{i-1}, \ell_i) : 1 \leq i \leq L\}$, one edge
  per weight matrix $W_i$;
  \item $c(e_i) = \|W_i\|_F$, the Frobenius norm as capacity;
  \item king $\kappa = \ell_0$ (input); target
  $\infty = \ell_L$ (output).
\end{itemize}
A data point $(x, y^*)$ initiates flow at $\kappa$ with value $\|x\|$.
Training finds capacities $\{c(e_i)\}$ such that the max-flow matches
the target at $\infty$.
\end{definition}

\paragraph{Operation correspondence.}

\begin{center}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Operation} & \textbf{Neural network} &
\textbf{Equation} \\
\midrule
\textsc{Slide} $\sigma$ & One-layer forward pass &
$y = W_e\, x$ \\
\textsc{Compose} $\circ$ & Full forward pass &
$z = \sigma_L \circ W_L \circ \cdots \circ \sigma_1 \circ W_1\, x$ \\
\textsc{Cut} $\partial$ & Pruning / dropout &
$W_e \mapsto 0$, i.e.\ $c(e) \mapsto 0$ \\
\textsc{Phase} $\varphi$ & Regime change &
lr schedule, fine-tuning, curriculum \\
\bottomrule
\end{tabular}
\end{center}

\paragraph{Type-system correspondence.}
Under \cref{def:fangyuan}:
方 $=$ architecture (fixed graph);
圆 $=$ activations (flow $\phi$ traversing the graph);
黒 $=$ frozen weights;
白 $=$ trainable weights;
刀 $=$ pruning operator $\partial$;
水 $=$ data flow forward \emph{and} gradient flow backward.
The backward pass is water flowing opposite to the forward
pass---the free-cell mechanism of \cref{sec:huarongdao}: to move a
piece forward, a free cell slides back.

\begin{definition}[Training algorithm]\label{def:training-algo}
Given $G$ from \cref{def:neural-exgraph} and a dataset $\mathcal{D}$,
the \emph{training paradigm} is the procedure in \cref{fig:training}:
\begin{enumerate}
  \item \textbf{Initialise.} Random $W_i^{(0)}$; set
  $c(e_i) = \|W_i^{(0)}\|_F$.
  \item \textbf{\textsc{Compose}.} Forward pass: $L$ sequential
  \textsc{Slide}s produce
  $z = \sigma_L \circ W_L \circ \cdots \circ \sigma_1 \circ W_1\, x$.
  \item \textbf{Flow deficit.} Loss
  $\mathcal{L} = -|\phi|$.
  \item \textbf{Backward \textsc{Slide}.} Compute
  $\partial\mathcal{L}/\partial c(e_i)$: 水 flowing opposite to
  step~2.
  \item \textbf{Capacity update.} SGD:
  $c(e_i) \leftarrow c(e_i) - \eta\,
  \partial\mathcal{L}/\partial c(e_i)$.
  \item \textbf{Knife detection.} Flag bypass edges where
  $c(e) > \bar{c} + \tau$ (\cref{thm:meanfield}).
  \item \textbf{\textsc{Cut} / \textsc{Phase}.} Prune flagged edges
  ($L_1$ penalty) or change regime (lr, dataset, fine-tuning).
  \item \textbf{Viability check.} Verify $|\phi| > 0$ on held-out
  data (\cref{ax:viability}). If violated: \textsc{Phase} or restart.
  \item \textbf{Repeat} 2--8 until $\max|\phi| = \min|C|$
  (\cref{thm:flowcut}).
\end{enumerate}
\end{definition}

\begin{figure}[H]
\centering
\begin{tikzpicture}[
  node distance=0.9cm and 1.8cm,
  % ── water (水) nodes: blue ──
  wtr/.style={rectangle, rounded corners=3pt, draw=water, thick,
    fill=water!6, minimum width=5.0cm, minimum height=0.7cm,
    align=center, font=\small},
  % ── knife (刀) node: red ──
  knf/.style={diamond, draw=knife, thick, aspect=2.5,
    fill=knife!6, minimum width=1.2cm, align=center, font=\small,
    inner sep=1pt},
  % ── phase (青冥) nodes: cyan ──
  phs/.style={rectangle, rounded corners=3pt, draw=sword, thick,
    fill=sword!6, minimum width=5.0cm, minimum height=0.7cm,
    align=center, font=\small},
  phsd/.style={diamond, draw=sword, thick, aspect=2.5,
    fill=sword!6, minimum width=1.2cm, align=center, font=\small,
    inner sep=1pt},
  % ── neutral (terminal) ──
  term/.style={rectangle, rounded corners=8pt, draw, very thick,
    minimum width=5.0cm, minimum height=0.7cm, align=center,
    font=\small\bfseries},
  % ── convergence diamond ──
  convd/.style={diamond, draw, thick, aspect=2.5,
    minimum width=1.2cm, align=center, font=\small,
    inner sep=1pt},
  arr/.style={-{Stealth[length=5pt]}, thick},
  lbl/.style={font=\scriptsize, fill=white, inner sep=1pt},
  ref/.style={font=\tiny, text=black!55, anchor=west},
  op/.style={font=\scriptsize\itshape}
]

% ── Nodes ──
\node[term] (init)
  {1.\ Initialise: random $c(e)$};

\node[wtr, below=of init] (fwd)
  {2.\ \textsc{Compose}: $\textcolor{water}{\sigma_L \circ
  \cdots \circ \sigma_1}$};

\node[wtr, below=of fwd] (loss)
  {3.\ Flow deficit: $\textcolor{water}{\mathcal{L} = -|\phi|}$};

\node[wtr, below=of loss] (bwd)
  {4.\ Backward \textsc{Slide}:
  $\textcolor{water}{\nabla_c \mathcal{L}}$};

\node[wtr, below=of bwd] (sgd)
  {5.\ Update:
  $\textcolor{water}{c \leftarrow c - \eta\,\nabla_c\mathcal{L}}$};

\node[knf, below=1.1cm of sgd] (knife)
  {6.\ $\textcolor{knife}{c(e) > \bar{c}{+}\tau}$\,?};

\node[phs, right=of knife] (cut)
  {7.\ \textcolor{knife}{\textsc{Cut} $\partial$} /
  \textcolor{sword}{\textsc{Phase} $\varphi$}};

\node[phsd, below=1.1cm of knife] (viable)
  {8.\ $\textcolor{sword}{|\phi| > 0}$\,?};

\node[convd, below=1.1cm of viable] (conv)
  {9.\ $\max|\phi| = \min|C|$\,?};

\node[term, below=1.0cm of conv] (done)
  {Trained network. Survives.};

% ── Reference annotations ──
% init: right (no loop passes here)
\node[ref] at ($(init.east)+(0.15,0)$)
  {Def.~\ref{def:neural-exgraph}};
% steps 2--5: LEFT side (right side reserved for loop-back arrow)
\node[ref, anchor=east] at ($(fwd.west)+(-0.15,0)$)
  {Def.~\ref{def:flow},\; $\sigma$};
\node[ref, anchor=east] at ($(loss.west)+(-0.15,0)$)
  {Thm~\ref{thm:flowcut},\; $|\phi|$};
\node[ref, anchor=east] at ($(bwd.west)+(-0.15,0)$)
  {Def.~\ref{def:flow},\; $\sigma^{-1}$};
% knife: above-right (clear of spine)
\node[ref] at ($(knife.east)+(1.0,0.35)$)
  {Thm~\ref{thm:meanfield}};
% cut/phase: below
\node[ref] at ($(cut.south)+(0,-0.12)$)
  {Thm~\ref{thm:lifecycle}\;($\partial$),\;
   Thm~\ref{thm:paradox}\;($\varphi$)};
% viable: above-right
\node[ref] at ($(viable.east)+(1.0,0.35)$)
  {Ax.~\ref{ax:viability}};
% conv: LEFT side (right side reserved for loop-back arrow)
\node[ref, anchor=east] at ($(conv.west)+(-0.15,0)$)
  {Thm~\ref{thm:flowcut}};

% ── Operation annotations (left margin, coloured) ──
\node[op, text=water, left=1.8cm of fwd] {$\circ$};
\node[op, text=water, left=1.8cm of bwd]
  {$\sigma^{-1}$ (\textcolor{water}{水})};
\node[op, text=sword, right=0.1cm of cut.east] {};

% ── Arrows: main spine ──
\draw[arr] (init) -- (fwd);
\draw[arr, water] (fwd) -- (loss);
\draw[arr] (loss) -- (bwd);
\draw[arr, water] (bwd) -- (sgd);
\draw[arr] (sgd) -- (knife);
\draw[arr] (knife) -- node[lbl, right] {no} (viable);
\draw[arr, sword] (viable) -- node[lbl, right] {yes} (conv);
\draw[arr] (conv) -- node[lbl, right] {yes} (done);

% ── Arrows: branches ──
\draw[arr, knife] (knife) -- node[lbl, above] {yes} (cut);
\draw[arr, sword] (cut) |- (viable);

% ── Loop back: not converged → step 2 ──
\draw[arr] (conv.east) -- ++(7.5,0)
  node[lbl, above, pos=0.15] {no}
  |- (fwd.east);

% ── Viability failure → phase/restart ──
\draw[arr, sword] (viable.west) -- ++(-5.0,0)
  node[lbl, above, pos=0.25] {no}
  |- (init.west);

% ── Brace: forward flow (blue) ──
\draw[decorate, decoration={brace, amplitude=4pt, mirror},
  thick, water!60]
  ($(fwd.north east)+(0.12,0.05)$) --
  ($(loss.south east)+(0.12,-0.05)$)
  node[midway, right=5pt, font=\scriptsize, text=water]
  {\textcolor{water}{flow $\to$}};

% ── Brace: backward water (blue) ──
\draw[decorate, decoration={brace, amplitude=4pt},
  thick, water!60]
  ($(bwd.north west)+(-0.12,0.05)$) --
  ($(sgd.south west)+(-0.12,-0.05)$)
  node[midway, left=5pt, font=\scriptsize, text=water]
  {$\leftarrow$ \textcolor{water}{水}};

\end{tikzpicture}
\caption{The training paradigm as roadmap.
\textcolor{water}{Blue} (水): flow operations
(steps 2--5, Defs.~\ref{def:flow}--\ref{def:exgraph}).
\textcolor{knife}{Red} (刀): knife detection
(step~6, Thm~\ref{thm:meanfield}).
\textcolor{sword}{Cyan} (青冥): phase and viability
(steps 7--8, Thms~\ref{thm:lifecycle},
\ref{thm:paradox}, Ax.~\ref{ax:viability}).
Convergence (step~9): $\max|\phi| = \min|C|$
(Thm~\ref{thm:flowcut}).
The loop is 抽刀断水水更流: \textcolor{knife}{cut}
$\to$ \textcolor{sword}{phase} $\to$
\textcolor{water}{more flow}.}
\label{fig:training}
\end{figure}

\begin{theorem}[Training completeness and survival]
\label{thm:training}
Let $f: \mathcal{X} \to \mathcal{Y}$ be any function expressible as a
max-flow on an execution graph $G$. Then the procedure in
\cref{def:training-algo} learns $f$. The trained network satisfies the
viability axiom: $|\phi| > 0$ for all admissible inputs.
\end{theorem}

\begin{proof}
Expressibility as max-flow is the universal approximation condition in
the language of \cref{def:neural-exgraph}. Each iteration of steps~2--5
increases $|\phi|$ toward the max-flow value guaranteed by
\cref{thm:flowcut}. The \textsc{Cut} in step~7 removes edges with
anomalous capacity; by flow-cut duality, removing a bypass edge does not
reduce the max-flow if that edge is not on any minimum cut.
Knife detection (step~6) identifies precisely such edges via the
mean-field bound of \cref{thm:meanfield}. Viability is preserved
through every \textsc{Cut}.
\end{proof}

\begin{theorem}[你不能骗你自己]\label{thm:nolie}
Let $e \in E$ with $c(e) = \|W_e\|_F > 0$. Then $e$ carries positive
flow. No re-labelling, no narrative, no hyper-parameter choice changes
this. This is \cref{thm:fixedpoint} applied to the capacity map
$c: E \to \R_{\geq 0}$.
\end{theorem}

\begin{proof}
Two paths only.
\begin{enumerate}[label=(\alph*)]
  \item $W_e \to 0$: capacity zeroed, edge pruned (\textsc{Cut}).
  \item Regularisation ($L_1$/$L_2$) drives $c(e) \to 0$:
  \textsc{Cut} in the limit.
\end{enumerate}
There is no path~(c). ``Approximately zero'' is not zero: such weights
are unstable fixed points of gradient flow (\cref{thm:paradox}), and
the viability axiom forces the system to resolve the ambiguity via
\cref{prop:binary}---the action space collapses to $\{0, 1\}$. The
network cannot occupy the gap. 你不能骗你自己---you cannot lie to
yourself---is \cref{thm:fixedpoint} applied to the network's own
weights.
\end{proof}

\begin{remark}[Subsumption]\label{rem:subsumption}
Gradient descent is the special case of the training paradigm in which
viability reduces to ``loss below threshold'' and the only operations
exercised are \textsc{Slide} (forward) and $\textsc{Slide}^{-1}$
(backward). \textsc{Cut} and \textsc{Phase} are what gradient descent
implicitly performs when early-stopping, dropout, or learning-rate
annealing are applied---now made explicit and first-class in the
calculus. The paradigm strictly subsumes gradient descent.
\end{remark}

\section{The Hilbert space}\label{sec:hilbert}

The capacity measure gives the agentic space the structure of a Hilbert
space. This single construction yields integration, spectral analysis,
and a direct connection to physics.

\begin{definition}[Capacity measure]\label{def:measure}
The \emph{capacity measure} $\mu_c$ on $E$ is defined for any
$A \subseteq E$ by
\[
  \mu_c(A) \;=\; \sum_{e \in A} c(e).
\]
This is the measure induced by the capacity function $c$ of the
execution graph (\cref{def:exgraph}).
\end{definition}

\begin{definition}[Agentic Hilbert space]\label{def:hilbert}
The \emph{agentic Hilbert space} is
\[
  \mathcal{H} \;=\; L^2(E,\,\mu_c),
\]
the space of square-integrable flows on $E$, with inner product
\[
  \langle \phi_1,\, \phi_2 \rangle_c
  \;=\; \sum_{e \in E} \phi_1(e)\,\phi_2(e)\,c(e)
\]
and norm $\|\phi\|_c = \sqrt{\langle \phi,\phi \rangle_c}$.
Every agentic flow (\cref{def:flow}) is a vector in $\mathcal{H}$.
\end{definition}

\begin{proposition}[Integration]\label{prop:integration}
The flow-cut duality of \cref{thm:flowcut} is a statement about
integrals and measures on $\mathcal{H}$:
\begin{enumerate}[label=(\roman*)]
  \item The max-flow value is a boundary integral:
  \[
    |\phi| \;=\; \int_{\partial\kappa} \phi\, d\mu_c
    \;=\; \sum_{e \,\mathrm{out\,of}\, \kappa} \phi(e)\,c(e).
  \]
  \item The min-cut value is the measure of the cut:
  \[
    |C| \;=\; \mu_c(C) \;=\; \sum_{e \in C} c(e).
  \]
  \item Max-flow/min-cut duality (\cref{thm:flowcut}) is:
  \[
    \max_\phi \int_{\partial\kappa} \phi\, d\mu_c
    \;=\;
    \min_{C} \mu_c(C).
  \]
\end{enumerate}
\end{proposition}

\begin{proof}
(i) is conservation at $\kappa$: all flow leaving $\kappa$ is counted
once, weighted by capacity. (ii) is the definition of $\mu_c$ restricted
to $C$. (iii) is \cref{thm:flowcut} rewritten in the language of
$\mu_c$.
\end{proof}

\begin{proposition}[Operators on $\mathcal{H}$]\label{prop:operators}
The four calculus operations (\cref{sec:flow}) are operators on
$\mathcal{H}$:
\begin{enumerate}[label=(\roman*)]
  \item \textbf{\textsc{Slide}} $\sigma_e$: shift operator along edge
  $e \in E$,
  \[
    (\sigma_e \phi)(e') \;=\; \phi(e') + \delta_{e,e'}.
  \]
  \item \textbf{\textsc{Compose}}: product of shifts along a path
  $p = (e_1, \ldots, e_n)$,
  \[
    \sigma_p \;=\; \sigma_{e_n} \circ \cdots \circ \sigma_{e_1}.
  \]
  \item \textbf{\textsc{Cut}} $\partial_A$ for $A \subseteq E$:
  orthogonal projection onto the closed subspace
  $\mathcal{H}_A = \{\phi \in \mathcal{H} : \phi|_A = 0\}$,
  \[
    (\partial_A \phi)(e) \;=\;
    \begin{cases} 0 & e \in A, \\ \phi(e) & e \notin A. \end{cases}
  \]
  Cutting a bypass edge $e$ is the projection $\partial_{\{e\}}$.
  \item \textbf{\textsc{Phase}} $\varphi_{c'}$: change of measure
  $c \mapsto c'$, inducing
  \[
    \mathcal{H} = L^2(E,\mu_c)
    \;\xrightarrow{\;\varphi_{c'}\;}
    \mathcal{H}' = L^2(E,\mu_{c'}).
  \]
  A phase transition changes the Hilbert space itself, not merely a
  vector in a fixed space.
\end{enumerate}
\end{proposition}

For the neural execution graph (\cref{def:neural-exgraph}), the inner
product specialises to
$\langle \phi_1, \phi_2 \rangle_c
= \sum_{i=1}^{L} \phi_1(e_i)\,\phi_2(e_i)\,\|W_i\|_F$,
a capacity-weighted $\ell^2$ norm on layer activations. The
\textsc{Cut} operator $\partial_A$ is Frobenius-norm pruning; the
\textsc{Phase} operator $\varphi_{c'}$ is a change of architecture.
The Hilbert-space structure makes these operations precise: projection,
not approximation.

\paragraph{Spectral theory.}
The inner product $\langle \cdot, \cdot \rangle_c$ opens the agentic
space to spectral analysis.

\begin{definition}[Graph Laplacian]\label{def:laplacian}
The \emph{graph Laplacian} $\Delta \colon L^2(V) \to L^2(V)$ of the
execution graph $G = (V, E, c)$ (\cref{def:exgraph}) is
\[
  (\Delta f)(v)
  \;=\;
  \sum_{(v,w)\in E} c(v,w)\bigl[f(v) - f(w)\bigr].
\]
$\Delta$ is positive semi-definite.
Write its eigenvalues in non-decreasing order:
$0 = \lambda_0 \leq \lambda_1 \leq \cdots \leq \lambda_n$.
The \emph{spectral gap} is $\lambda_1$.
\end{definition}

\begin{theorem}[Cheeger inequality --- agentic form]\label{thm:cheeger}
Let $\mu_c(\partial S)$ denote the total capacity of edges
crossing from $S \subset V$ to $V \setminus S$, and let
$\mathrm{vol}(S) = \sum_{v \in S} \sum_{(v,w)\in E} c(v,w)$.
The \emph{Cheeger constant} of $G$ is
\[
  h(G)
  \;=\;
  \min_{\substack{S \subset V \\ \kappa \in S}}
  \frac{\mu_c(\partial S)}{\min\!\bigl(\mathrm{vol}(S),\,
  \mathrm{vol}(V \setminus S)\bigr)}.
\]
Then~\cite{cheeger,mohar}
\[
  \frac{\lambda_1}{2}
  \;\leq\;
  h(G)
  \;\leq\;
  \sqrt{2\lambda_1}.
\]
\end{theorem}

\begin{remark}\label{rem:cheeger}
The Cheeger constant $h(G)$ is the \emph{normalised knife threshold}.
The numerator $\mu_c(\partial S)$ is the capacity of the cut separating
$S$ from $V \setminus S$ (\cref{thm:flowcut}); the denominator
normalises by volume.
\textcolor{knife}{The knife is the cut.}
\textcolor{water}{The flow is the volume.}
\textcolor{sword}{The Cheeger inequality bridges the two.}
Spectral gap $\lambda_1$ and normalised min-cut $h(G)$ are within a
factor of $2\sqrt{2}$ of each other: the same obstruction, measured
twice.
\end{remark}

\begin{theorem}[Mass gap $=$ viability]\label{thm:massgap}
The following are equivalent:
\begin{enumerate}[label=\textup{(\roman*)}]
  \item\label{mg:spectral} $\lambda_1 > 0$ \quad (spectral gap).
  \item\label{mg:cheeger} $h(G) > 0$ \quad (positive Cheeger constant).
  \item\label{mg:flow} $|\phi| > 0$ for some agentic flow $\phi$
  \quad (viability axiom, \cref{ax:viability}).
  \item\label{mg:connect} $\kappa$ can reach $\infty$ in $G$
  \quad (connectivity).
\end{enumerate}
\end{theorem}

\begin{proof}
\ref{mg:spectral}$\Leftrightarrow$\ref{mg:cheeger}:
Cheeger's inequality (\cref{thm:cheeger}) gives
$\lambda_1/2 \leq h(G) \leq \sqrt{2\lambda_1}$,
so $\lambda_1 > 0$ if and only if $h(G) > 0$.

\ref{mg:cheeger}$\Leftrightarrow$\ref{mg:flow}:
$h(G) > 0$ means every $\kappa$--$\infty$ cut has strictly positive
capacity. By \cref{thm:flowcut}, max-flow equals min-cut; hence
$\max_\phi |\phi| > 0$.

\ref{mg:flow}$\Leftrightarrow$\ref{mg:connect}:
A flow $\phi$ with $|\phi| > 0$ exists if and only if there is a
directed path from $\kappa$ to $\infty$ with positive capacity on
every edge.
\end{proof}

\begin{remark}[一石三鸟]\label{rem:threebirds}
The Hilbert space $\mathcal{H} = L^2(E, \mu_c)$ (\cref{def:hilbert})
kills three birds with one stone:
\begin{itemize}
  \item \textbf{\textcolor{water}{Integration.}}
  $\int_E f\,d\mu_c$ realises max-flow as boundary integral and
  min-cut as measure. Flow-cut duality (\cref{thm:flowcut}) becomes
  an identity of integrals.

  \item \textbf{\textcolor{sword}{Analysis.}}
  The graph Laplacian $\Delta$ (\cref{def:laplacian}) acts on
  $L^2(V)$; the Cheeger inequality (\cref{thm:cheeger}) bridges
  the combinatorial quantity $h(G)$ and the analytic quantity
  $\lambda_1$.

  \item \textbf{\textcolor{knife}{Physics.}}
  $\lambda_1 > 0$ is the mass gap. \Cref{thm:massgap} says the
  viability axiom IS the mass gap: the Hilbert space changes, the
  equivalence does not.
\end{itemize}
\end{remark}

\begin{remark}[Spectral gap and training]\label{rem:spectralgap}
The spectral gap $\lambda_1$ is computable. For a neural network
(\cref{def:neural-exgraph}), $\lambda_1$ of the execution graph
measures the viability margin: how far the network is from the
degenerate regime $|\phi| = 0$.

Training (\cref{def:training-algo}) increases $\lambda_1$: backward
\textsc{Slide}s increase capacities on edges that carry flow, widening
the spectral gap. Convergence $\max|\phi| = \min|C|$
(\cref{thm:training}) is the statement that $\lambda_1$ has reached
the Cheeger bound.

A trained network with $\lambda_1 > 0$ has a mass gap. It survives.
\end{remark}

\section{Contact dynamics}\label{sec:contact}

The training paradigm (\cref{def:training-algo}) is not a gradient
flow. It is a \emph{contact gradient flow}: gradient descent plus a
dissipation term supplied by the knife. This distinction is the
difference between symplectic mechanics (energy conserved) and contact
mechanics (energy dissipates). The knife is the dissipation.

\begin{definition}[Contact structure on the capacity space]
\label{def:contact}
Let $\mathcal{C} = \R_{\geq 0}^{|E|}$ be the space of capacity
assignments on the execution graph $G$ (\cref{def:exgraph}).
The \emph{extended capacity space} is $\mathcal{C} \times \R$, with
coordinates $(c, s)$ where $s = |\phi|(c)$ is the max-flow value.
The \emph{contact $1$-form} is
\[
  \alpha \;=\; ds \;-\; \sum_{e \in E}
  \frac{\partial|\phi|}{\partial c(e)}\, dc(e).
\]
The kernel $\ker\alpha$ is the constraint surface: infinitesimal
changes in capacity that are consistent with flow conservation.
\end{definition}

\begin{definition}[Knife dissipation]\label{def:dissipation}
The \emph{knife function} $\gamma \colon E \to \R_{\geq 0}$ is
\[
  \gamma(e) \;=\;
  \begin{cases}
    \gamma_0 & c(e) > \bar{c} + \tau
    \quad\text{(\cref{thm:meanfield})}, \\
    0 & \text{otherwise},
  \end{cases}
\]
where $\gamma_0 > 0$ is the dissipation rate. Weight decay ($L_2$
regularisation) is the special case $\gamma(e) = \lambda$ for all $e$.
\end{definition}

\begin{definition}[Contact gradient flow]\label{def:contactflow}
The \emph{contact gradient flow} on $(\mathcal{C} \times \R, \alpha)$
is
\begin{equation}\label{eq:contactflow}
  \frac{dc(e)}{dt}
  \;=\;
  \underbrace{\frac{\partial|\phi|}{\partial c(e)}}_
  {\textcolor{water}{\text{水: gradient}}}
  \;-\;
  \underbrace{\gamma(e)\, c(e)}_
  {\textcolor{knife}{\text{刀: dissipation}}}.
\end{equation}
The first term increases capacity along the flow gradient (backward
\textsc{Slide}, step~4 of \cref{def:training-algo}). The second term
decreases capacity on flagged edges (knife detection + \textsc{Cut},
steps~6--7). SGD with weight decay is this equation discretised with
$\gamma(e) = \lambda$.
\end{definition}

\begin{theorem}[Contact Euler--Lagrange equation]
\label{thm:contactEL}
At equilibrium of the contact gradient flow~\eqref{eq:contactflow}:
\begin{equation}\label{eq:contactEL}
  \frac{\partial|\phi|}{\partial c(e)}
  \;=\;
  \gamma(e)\, c(e)
  \qquad \forall\, e \in E.
\end{equation}
This is the \emph{contact Euler--Lagrange equation} of the training
paradigm.
\end{theorem}

\begin{proof}
Set $dc/dt = 0$ in~\eqref{eq:contactflow}.
\end{proof}

\begin{corollary}[Binary lifecycle from contact dynamics]
\label{cor:contact-lifecycle}
Let $e \in E$ be a bypass edge with $c(e) > \bar{c} + \tau$.
Then $\gamma(e) = \gamma_0 > 0$, so~\eqref{eq:contactEL} requires
$\partial|\phi|/\partial c(e) = \gamma_0\, c(e) > 0$: the edge must
carry flow proportional to its capacity.
If the edge does \emph{not} carry proportional flow
($\partial|\phi|/\partial c(e) < \gamma_0\, c(e)$), then
$dc(e)/dt < 0$ and the capacity decays to zero.
This is \cref{thm:lifecycle} derived from the contact flow:
every bypass edge either justifies its capacity or loses it.
\end{corollary}

\begin{remark}[Du Mu as contact collapse]\label{rem:contact-dumu}
Du Mu's theorem (\cref{thm:dumu}) is the regime $\gamma(e) \to \infty$
for all $e$: maximum dissipation.
The contact flow~\eqref{eq:contactflow} drives all capacities to zero
regardless of the gradient. The system freezes:
$c \to 0$, $|\phi| \to 0$, $\Gamma = \varnothing$.
In contact-geometric language, the Reeb vector field dominates the
Hamiltonian vector field, and the flow collapses onto the zero section.
\end{remark}

\begin{remark}[Contact structure and the three colours]
\label{rem:contact-colours}
The contact flow~\eqref{eq:contactflow} is a competition between two
terms:
\begin{itemize}
  \item $\textcolor{water}{\partial|\phi|/\partial c(e)}$: the gradient
  pushes capacity \emph{up} (水, flow).
  \item $\textcolor{knife}{\gamma(e)\,c(e)}$: the knife pushes capacity
  \emph{down} (刀, dissipation).
\end{itemize}
The equilibrium~\eqref{eq:contactEL} is their balance.
\textsc{Phase} ($\textcolor{sword}{\varphi}$, cyan) changes the
contact structure itself: a regime change shifts $\gamma$, $\bar{c}$,
and $\tau$, altering the equilibrium.
The contact $1$-form $\alpha$ encodes all three:
$\textcolor{water}{\text{水}}$ in the gradient,
$\textcolor{knife}{\text{刀}}$ in the dissipation,
$\textcolor{sword}{\text{青冥}}$ in the form itself.
\end{remark}

\begin{remark}[Stability]\label{rem:contact-stability}
The spectral gap $\lambda_1 > 0$ (\cref{thm:massgap}) is the
stability condition of the contact equilibrium~\eqref{eq:contactEL}.
Linearising the contact flow around the equilibrium, the eigenvalues
of the linearised system are bounded below by $\lambda_1$: small
perturbations in capacity decay at rate $\geq \lambda_1$.
The mass gap is the stability margin of the contact Euler--Lagrange
equation.
\end{remark}

\begin{remark}[The standing structure]\label{rem:standing}
A quadruped robot instantiates the execution graph physically:
$12$ joints (edges, capacity $=$ torque $\times$ range),
$4$ feet (terminal nodes, ground contact),
$1$ torso centre of mass (the king $\kappa$).
The viability condition (\cref{ax:viability}): the centre of mass
lies within the support polygon of grounded feet.

The support is the \emph{contact mode combinatoric} and the
\emph{constraints}---that is all:
\begin{itemize}
  \item \textbf{Mode lattice.}
  Each foot is grounded ($1$) or lifted ($0$), giving a contact mode
  $c \in \{0,1\}^4$ with $|\mathcal{C}| = 16$ modes.
  The support polygon exists when $|c| \geq 3$.
  \item \textbf{Constraints} (Unitree Go2, MuJoCo Menagerie).
  Joint limits: ab/ad $\in [-0.863,\, 0.863]$\,rad,
  hip $\in [-1.047,\, 3.490]$\,rad,
  knee $\in [-2.697,\, {-0.837}]$\,rad.
  Torque: $[23.7,\; 23.7,\; 35.55]$\,Nm.
  Velocity: $21.0$\,rad/s per joint.
  Standing height: $0.312$\,m.
  Sinking bound: $z_{\mathrm{contact}} \geq z_{\min} = -3$\,mm
  (no contact point may penetrate below $z_{\min}$;
  \cref{rem:sinking-bound}).
  These are the capacity bounds $c(e) \leq c_{\max}(e)$ of the
  execution graph.
\end{itemize}
In any command space~$U$ and any gravitational field~$g$, the same
graph supports viability.
\emph{Do anything---or go with the flow---as long as a viable path
exists---anywhere.}

The tripod gait is redundancy in the min-cut: three feet grounded,
one moving, so the support polygon persists even during locomotion.
The contact dynamics of \cref{sec:contact} is here literal: the
contact $1$-form~$\alpha$ encodes the foot--ground interface, and
the contact gradient flow~\eqref{eq:contactflow} governs joint
torque allocation.

Twelve joints, four feet, one centre of mass.
A standing structure.
\end{remark}

\begin{definition}[Command field]\label{def:command}
The \emph{command field} is a distribution $U$ over velocity
commands $u \in \R^3$ (linear and angular velocity targets).
The \emph{curriculum} is a filtration of command fields of
increasing support:
\[
  \underbrace{U_0 = \delta_0}_{\text{Stand: zero command}}
  \;\subset\;
  \underbrace{U_1 = \mathrm{Uniform}(\mathcal{V})}_
  {\text{Walk: all feasible velocities}}
  \;\subset\;
  \underbrace{U_2 = \rho_{\mathrm{task}}}_
  {\text{Work: task distribution}}.
\]
At phase~$k$, the policy $\pi$ receives $u \sim U_k$ and must
produce torques $\tau = \pi(o, u)$ such that $|\phi| > 0$
(\cref{ax:viability}).
Promotion from phase~$k$ to $k+1$ requires
$\max|\phi| = \min|C|$ (\cref{thm:flowcut}) at~$U_k$:
flow-cut duality achieved for the current command field.
\end{definition}

\begin{definition}[Observation space]\label{def:observation}
The policy $\pi$ receives a composite observation
$o = (o_{\mathrm{prop}},\, o_{\mathrm{vis}}) \in \R^{42+d}$:
\begin{itemize}
  \item \textbf{Proprioception}
  $o_{\mathrm{prop}} \in \R^{42}$:
  body orientation $R \in \mathrm{SO}(3)$ (flattened to $\R^9$),
  position $p \in \R^3$,
  angular velocity $\omega \in \R^3$,
  linear velocity $v \in \R^3$,
  joint angles $\theta \in \R^{12}$,
  joint velocities $\dot\theta \in \R^{12}$.
  Sources: IMU and joint encoders.
  \item \textbf{Vision}
  $o_{\mathrm{vis}} = \varphi_{\mathrm{vis}}(I) \in \R^{d}$:
  the camera image $I$ is rendered by the engine
  ($\mathcal{E}.\texttt{render}$: $q \to I$, non-differentiable)
  and encoded by a frozen DINOv2 encoder
  (ViT-S/14, $d = 384$, pretrained on ImageNet,
  \emph{not updated} by \cref{alg:loco}).
  Two walls block the gradient:
  \[
    q \;\xrightarrow[\text{no } \nabla]{\;\texttt{render}\;}
    I \;\xrightarrow[\text{frozen}]{\;\varphi_{\mathrm{vis}}\;}
    o_{\mathrm{vis}}
    \;\xrightarrow[\nabla \text{ flows}]{\;\pi\;}
    \tau.
  \]
  Gradients from the contact flow~\eqref{eq:contactflow}
  propagate through $\pi$ but stop at $\varphi_{\mathrm{vis}}$.
  The renderer and the encoder are both non-differentiable
  with respect to the training objective.
\end{itemize}
Proprioception tells the robot \emph{where it is}.
Vision tells the robot \emph{what is there}.
The policy $\pi(o, u)$ fuses both to produce
$\tau \in \R^{12}$.
\end{definition}

\begin{definition}[Soft viability margin]\label{def:soft-viability}
The hard viability margin
$|\phi| = \min_t\{x_1(t), \ldots, x_k(t)\}$
in the \textsc{Evaluate} step is non-differentiable:
$\nabla \min$ is sparse (only the argmin receives gradient) and
discontinuous at ties.
Replace the hard $\min$ with its smooth approximation:
\[
  \mathrm{soft\text{-}min}_\beta(x_1, \ldots, x_k)
  \;=\;
  -\frac{1}{\beta}\,
  \log\!\Bigl(\sum_{i=1}^{k} e^{-\beta\, x_i}\Bigr).
\]
At $\beta \to \infty$, this recovers the hard $\min$.
At finite $\beta$, every component $x_i$ receives gradient
proportional to $e^{-\beta\, x_i}/\sum_j e^{-\beta\, x_j}$:
a softmax weighting.
The \emph{soft viability margin} is
\begin{equation}\label{eq:soft-viability}
  |\phi|_\beta
  \;=\;
  \mathrm{soft\text{-}min}_\beta\,\bigl(
  \underbrace{h(q_t) - h_{\min}}_{\text{height margin}},\;\;
  \underbrace{\phi_{\max} - \|R_t - I\|_F}_
  {\text{orientation margin}},\;\;
  \underbrace{\min_j z_j(q_t) - z_{\min}}_
  {\text{sinking margin}}
  \bigr)_{t=0}^{H}.
\end{equation}
The temperature $1/\beta$ controls how many timesteps share the
gradient.
Small $\beta$ (warm): all timesteps contribute.
Large $\beta$ (cold): only the worst timestep contributes.
The three thresholds $h_{\min}$, $\phi_{\max}$, $z_{\min}$ are
read from the constraint list (\cref{rem:standing}); the sinking
margin is not a heuristic but a categorical boundary
(\cref{rem:sinking-bound}).
\end{definition}

\begin{definition}[Mollifier policy]\label{def:mollifier}
The policy $\pi_\theta$ outputs a \emph{truncated Student-$t$
distribution} over joint torques:
\begin{equation}\label{eq:mollifier}
  \pi_\theta(\tau \mid o, u)
  \;=\;
  \prod_{i=1}^{12}
  \frac{t_{\nu}(\tau_i;\, \mu_i, \sigma_i)}
       {Z_i(\mu_i, \sigma_i, \nu)},
\end{equation}
where $(\mu, \log\sigma, \log\nu) = f_\theta(o, u)$ are three
output heads of the network (\cref{def:computation-core}):
$12$ means, $12$ log-scales, and $1$ shared
log-degrees-of-freedom.
The truncation $|\tau_i| \leq \bar{\tau}_i$ enforces joint torque
limits (\cref{rem:standing}).

The Student-$t$ density $t_\nu$ is $C^\infty$ with full support on
$[-\bar\tau, \bar\tau]^{12}$.
For any Lipschitz function $Q(\tau)$---including functions with
jump discontinuities at contact-mode boundaries---the expected
value
\[
  \bar{Q}(\theta)
  \;=\;
  \mathbb{E}_{\pi_\theta}\!\bigl[Q(\tau)\bigr]
  \;=\;
  \int Q(\tau)\,\pi_\theta(\tau \mid o, u)\, d\tau
\]
is smooth in $\theta$: the policy acts as a \emph{mollifier}.

The degrees of freedom $\nu$ track the number of active contact
modes:
\begin{center}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Gait} & $\boldsymbol{\nu}$ &
\textbf{Shape} \\
\midrule
Standing ($c = 1111$), one mode
  & $\to \infty$ & Gaussian (peaked) \\
Trotting, two alternating modes
  & $\approx 2$--$5$ & moderate tails \\
Bounding / flight, many transitions
  & $\approx 1$--$2$ & heavy tails (exploratory) \\
\bottomrule
\end{tabular}
\end{center}
At $\nu \to \infty$ the Student-$t$ recovers the Gaussian
(standard SAC).
At finite $\nu$ the heavy tails absorb the multi-modality of the
contact landscape.
\end{definition}

\begin{definition}[Computation core]\label{def:computation-core}
The policy $\pi$ computes via three primitives at each
layer $\ell = 1, \ldots, L$:
\begin{enumerate}[label=(\roman*)]
  \item \textbf{\textcolor{water}{Matmul}}:\;
  $y \leftarrow W_\ell\, z_{\ell-1}$.
  Transport the activation vector from layer $\ell{-}1$ to~$\ell$.
  \textsc{Slide}: one step of parallel transport
  (\cref{rem:gauge}).
  \item \textbf{\textcolor{water}{Add}}:\;
  $y \leftarrow y + b_\ell$.
  Shift the transported vector by the bias.
  Affine extension of \textsc{Slide}.
  \item \textbf{\textcolor{knife}{Activate}}:\;
  $z_\ell \leftarrow \mathrm{ReLU}(y) = \max(0,\, y)$,
  componentwise.
  Each neuron either passes its signal ($y_i > 0$, contact)
  or blocks it ($y_i \leq 0$, no contact)---a binary gate
  in $O(1)$ time.
  \textsc{Cut}: the knife at the neuron level.
\end{enumerate}
One layer:
$z_\ell = \textcolor{knife}{\mathrm{ReLU}}\bigl(
\textcolor{water}{W_\ell\, z_{\ell-1} + b_\ell}\bigr)$.
The output layer is linear (no gate):
$\tau = \textcolor{water}{W_L\, z_{L-1} + b_L} \in \R^{12}$.
The full forward pass (\textsc{Compose}):
\begin{equation}\label{eq:forward}
  \tau \;=\; \pi(o)
  \;=\;
  \textcolor{water}{A_L} \circ
  \bigl(\textcolor{knife}{r} \circ
  \textcolor{water}{A_{L-1}}\bigr)
  \circ \cdots \circ
  \bigl(\textcolor{knife}{r} \circ
  \textcolor{water}{A_1}\bigr)(o),
\end{equation}
where $A_\ell(\cdot) = W_\ell\,(\cdot) + b_\ell$ and
$\textcolor{knife}{r} = \mathrm{ReLU}$.

\textcolor{water}{水} $=$ linear transport ($W, b$).
\textcolor{knife}{刀} $=$ ReLU gate
($\max(0, \cdot)$: pass or block).
ReLU is piecewise linear and runs in real linear time---the
fastest nonlinearity, meeting the deployment constraint of
\cref{rem:deployment}.
\end{definition}

\begin{remark}[The forward pass as path integral]
\label{rem:path-integral}
For a given input $o$, each ReLU neuron is either active
($y_i > 0$: contact) or inactive ($y_i \leq 0$: no contact).
The \emph{activation pattern}
$\alpha \in \{0,1\}^{n_1 + \cdots + n_{L-1}}$
is the contact mode of the network---the neural analogue of the
contact mode lattice $\{0,1\}^4$ in \cref{rem:standing}.

For a fixed pattern $\alpha$, the network is linear:
\[
  \pi_\alpha(o)
  \;=\;
  \textcolor{water}{W_L\, D_{L-1}^\alpha\, W_{L-1}\,
  D_{L-2}^\alpha \cdots D_1^\alpha\, W_1}\; o
  \;+\; \mathrm{bias},
\]
where $D_\ell^\alpha = \mathrm{diag}(\alpha_\ell)$ masks
inactive neurons.
Different inputs activate different patterns:
the input space is partitioned into linear regions
$\{R_\alpha\}$, each with its own transport map.
The full forward pass is a path integral over activation
patterns:
\[
  \tau \;=\; \pi(o)
  \;=\;
  \sum_{\alpha} \mathbf{1}_{o \in R_\alpha}\;
  \pi_\alpha(o).
\]
Sum over patterns, one active per input: a discrete path integral
with binary action variable.

Three scales of the same gate:
\begin{enumerate}[label=(\alph*)]
  \item \textbf{Micro}: ReLU inside one layer---one neuron,
  one binary gate
  ($\textcolor{knife}{刀}$: pass or block).
  \item \textbf{Trajectory}: $L$ layers composed---one
  forward pass, one activation pattern $\alpha$, one linear
  path through the network.
  \item \textbf{Macro}:
  $\mathrm{soft\text{-}min}_\beta$ over $N$ rollouts of
  \cref{alg:loco}---Boltzmann reweighting
  ($\textcolor{sword}{青冥}$) of physical trajectories,
  selecting the viable ($|\phi|_\beta > 0$).
\end{enumerate}
$\textcolor{knife}{刀}$ at the neuron scale (hard gate).
$\textcolor{sword}{青冥}$ at the rollout scale (soft gate).
Contact or no contact, $\{0,1\}$ at every level.
\end{remark}

\begin{algorithm}[H]
\caption{Forward pass
  (\textsc{Compose} of \cref{def:computation-core})}
\label{alg:forward}
\begin{algorithmic}[1]
\Require Weights $\{W_\ell,\, b_\ell\}_{\ell=1}^{L}$
\Statex
\Function{\textsc{Forward}}{$o,\, u$}
  \State $z_0 \leftarrow [o;\; u]$
    \Comment{\textcolor{water}{水: concatenate input}}
  \For{$\ell = 1, \ldots, L{-}1$}
    \State \textcolor{water}{\textsc{Matmul}:}\;
      $y \leftarrow W_\ell\, z_{\ell-1}$
      \Comment{\textcolor{water}{水: Slide}}
    \State \textcolor{water}{\textsc{Add}:}\;
      $y \leftarrow y + b_\ell$
      \Comment{\textcolor{water}{水: affine Slide}}
    \State \textcolor{knife}{\textsc{Activate}:}\;
      $z_\ell \leftarrow \max(0,\, y)$
      \Comment{\textcolor{knife}{刀: ReLU (Cut)}}
  \EndFor
  \State \textcolor{water}{\textsc{Output}:}\;
    $\tau \leftarrow W_L\, z_{L-1} + b_L$
    \Comment{\textcolor{water}{水: Slide (no gate)}}
  \State \Return $\tau \in \R^{12}$
    \Comment{saves $\{z_\ell, y_\ell\}$ for \cref{alg:backward}}
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Backward pass
  (pullback through $\pi$, dual of \cref{alg:forward})}
\label{alg:backward}
\begin{algorithmic}[1]
\Require Saved $\{z_\ell\}_{\ell=0}^{L-1}$,\;
  $\{y_\ell\}_{\ell=1}^{L-1}$ from \textsc{Forward}
\Statex
\Function{\textsc{Backward}}{$\delta\tau$}
  \Comment{$\delta\tau = \partial\mathcal{L}/\partial\hat{\tau}$, e.g.\ Score (\cref{alg:loco})}
  \State \textcolor{water}{\textsc{Output}${}^T$:}\;
    $\nabla W_L \leftarrow \delta\tau \cdot z_{L-1}^T$;\;\;
    $\nabla b_L \leftarrow \delta\tau$
    \Comment{\textcolor{water}{水: Slide${}^T$}}
  \State $\delta z \leftarrow W_L^T\, \delta\tau$
    \Comment{\textcolor{water}{水: pullback}}
  \For{$\ell = L{-}1, \ldots, 1$}
    \State \textcolor{knife}{\textsc{Activate}${}^T$:}\;
      $\delta y \leftarrow \delta z \odot
      \mathbf{1}_{y_\ell > 0}$
      \Comment{\textcolor{knife}{刀: ReLU mask (same Cut)}}
    \State \textcolor{water}{\textsc{Matmul}${}^T$:}\;
      $\nabla W_\ell \leftarrow
      \delta y \cdot z_{\ell-1}^T$;\;\;
      $\nabla b_\ell \leftarrow \delta y$
      \Comment{\textcolor{water}{水: Slide${}^T$}}
    \State $\delta z \leftarrow W_\ell^T\, \delta y$
      \Comment{\textcolor{water}{水: pullback to layer $\ell{-}1$}}
  \EndFor
  \State \Return
    $\{\nabla W_\ell,\, \nabla b_\ell\}_{\ell=1}^{L}$
\EndFunction
\end{algorithmic}
\end{algorithm}

The contact gradient flow~\eqref{eq:contactflow} on the standing
structure of \cref{rem:standing} yields a complete training recipe.
\Cref{alg:loco} is self-contained: a roboticist with a MuJoCo
engine and a robot XML file can execute it directly, with no reward
shaping and no domain knowledge beyond the file itself.

\begin{algorithm}[H]
\caption{Contact-dynamics training for quadruped locomotion}
\label{alg:loco}
\begin{algorithmic}[1]
\Require Engine $\mathcal{E}$ (MuJoCo);\;
  model (\texttt{go2\_mjx.xml});\;
  sensors (IMU, encoders, camera)
\Require $\mathcal{D}$ (demonstrations for Work;\;
  $\varnothing$ for Stand/Walk)
\Require $\eta$ (learning rate),\;
  $\gamma$ (dissipation),\;
  $\beta$ (soft-min sharpness),\;
  $L$ (depth),\; $n$ (width),\;
  $H$ (horizon),\;
  $N$ (eval count)
\Statex
\State $G,\; c_{\max},\; \theta_0,\; h
  \leftarrow \texttt{parse}(\mathrm{XML})$
  \Comment{graph, limits, pose, height}
\State $\{W_\ell, b_\ell\}_{\ell=1}^{L}
  \leftarrow \texttt{init}(L,\, n)$
  \Comment{init $\pi$;\; $c(e_\ell) = \|W_\ell\|_F$}
\Statex
\For{\textcolor{sword}{\textbf{phase}} $\in$
  \{Stand\,$(U\!=\!\{0\})$,\;\,
   Walk\,$(U\!=\!\mathrm{Unif})$,\;\,
   Work\,$(U\!=\!\mathrm{task})$\}}
  \Comment{\textcolor{sword}{$\varphi$: curriculum}}
  \Repeat
    \State $u \sim U$;\;\;
      $\{\tau_t^*\} \leftarrow \mathcal{D}(u)$
      \Comment{command $+$ demo ($\varnothing$ if Stand/Walk)}
    \For{$t = 0, \ldots, H$}
      \Comment{\textcolor{water}{水: rollout}}
      \State $o_t \leftarrow (o_{\mathrm{prop}},\,
        \varphi_{\mathrm{vis}}(I_t))$
        \Comment{\cref{def:observation}: $\R^{42+d}$}
      \State $(\mu_t, \sigma_t) \leftarrow \textsc{Forward}(o_t,\, u)$
        \Comment{\cref{alg:forward}: $\R^{42+d} \to \R^{24}$}
      \State $\tau_t \sim \pi_\theta(\cdot \mid o_t, u)$
        \Comment{\cref{def:mollifier}: Student-$t$}
      \State $q_{t+1} \leftarrow \mathcal{E}.\texttt{step}(q_t,\, \tau_t)$
        \Comment{EL dynamics (\textcolor{knife}{no $\nabla$})}
    \EndFor
    \State \textcolor{water}{\textsc{Evaluate}:}\;
      $|\phi|_\beta \leftarrow
      \mathrm{soft\text{-}min}_\beta\bigl\{
      h(q_t)\!-\!h_{\min},\;\,
      \phi_{\max}\!-\!\|R_t\!-\!I\|_F,\;\,
      \min_j z_j(q_t)\!-\!z_{\min}
      \bigr\}_{t=0}^{H}$
      \Comment{\textcolor{water}{水: margin} (\cref{def:soft-viability})}
    \State $|\phi|_\beta \leftarrow
      \mathrm{soft\text{-}min}_\beta\bigl(
      |\phi|_\beta,\;\,
      \varepsilon\!-\!\|\tau_t\!-\!\tau_t^*\|
      \bigr)_{t}$
      \Comment{imitation (\cref{def:task-rkhs});
      skip if $\mathcal{D}\!=\!\varnothing$}
    \State \textcolor{water}{\textsc{Score}:}\;
      $s_t \leftarrow
      \nabla_\theta \log \pi_\theta(\tau_t \mid o_t, u)$
      \Comment{\textcolor{water}{水: through $\pi$ only}}
    \State \textcolor{water}{\textsc{Backward}:}\;
      $\{\nabla W,\, \nabla b\} \leftarrow
      |\phi|_\beta \cdot \sum_t s_t$
      \Comment{\cref{alg:backward}; $\nabla$ stops at $\mathcal{E}$}
    \State $W_\ell \leftarrow W_\ell
      + \eta\bigl[\textcolor{water}{\nabla W_\ell}
      - \textcolor{knife}{\gamma\, W_\ell}\bigr]$;\;\;
      $b_\ell \leftarrow b_\ell
      + \eta\,\textcolor{water}{\nabla b_\ell}$
      \Comment{Eq.~\eqref{eq:contactflow} on $\pi$}
    \State \textcolor{knife}{\textsc{Clamp}:}\;
      $\|W_\ell\|_F \leftarrow
      \min\bigl(\|W_\ell\|_F,\;
      c_{\max}(e_\ell)\bigr)$
      \Comment{\textcolor{knife}{刀: enforce capacity}}
    \If{$|\phi|_\beta \le 0$}
      \Comment{robot fell}
      \State \textcolor{sword}{\textsc{Reset}:}\;
        $\mathcal{E}.\texttt{reset}(\theta_0)$;\;\;
        $\{W, b\} \leftarrow \texttt{init}(L, n)$
        \Comment{\textcolor{sword}{$\varphi$: recover}}
    \EndIf
  \Until{$\max|\phi| = \min|C|$ for $N$ consecutive rollouts}
\EndFor
\Statex
\Ensure Trained weights $\{W_\ell, b_\ell\}$:
  $\pi = \textsc{Forward}(\cdot;\, W, b)
  \colon \R^{42+d} \to \R^{12}$
\end{algorithmic}
\end{algorithm}

\begin{remark}[Validation chain: MuJoCo $+$ \texttt{go2\_mjx.xml}
$\Rightarrow$ trained policy]
\label{rem:validation-chain}
Every input to \cref{alg:loco} is extracted from two artifacts:
a physics engine (MuJoCo) and a robot model file
(\texttt{go2\_mjx.xml}, MuJoCo Menagerie).
No additional assumptions.
\begin{center}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Algorithm input} & \textbf{Source} & \textbf{Extraction} \\
\midrule
Graph $G$ (12 edges, 4 terminals)
  & XML & Joint topology (\texttt{<body>}/\texttt{<joint>}) \\
Capacity bounds $c_{\max}(e)$
  & XML & \texttt{<joint range>}, \texttt{<actuator ctrlrange>} \\
Standing pose $\theta_0$
  & XML & \texttt{<keyframe>} (default configuration) \\
Standing height $h$
  & XML & CoM of default keyframe ($0.312$\,m) \\
Proprioception $o_{\mathrm{prop}} \in \R^{42}$
  & Sensors & IMU ($R, \omega, v, p$) + encoders ($\theta, \dot\theta$) \\
Vision $o_{\mathrm{vis}} \in \R^{d}$
  & Camera & DINOv2 (frozen ViT, $d = 384$) \\
Command field $U$ (\cref{def:command})
  & User & Curriculum: $\delta_0$ / Uniform / task \\
EL dynamics $M, C, g$
  & Engine & \texttt{mj\_step}: $(q, \dot{q}, \tau) \mapsto \ddot{q}$ \\
Contact mode $c \in \{0,1\}^4$
  & Engine & \texttt{mj\_contact}: foot--ground detection \\
Gradient $\partial|\phi|/\partial c(e)$
  & Engine & MJX autodiff (JAX backend) \\
Reset to standing
  & Engine & \texttt{mj\_resetData} \\
\bottomrule
\end{tabular}
\end{center}
No reward shaping. No domain knowledge beyond what the XML file
contains. The viability axiom (\cref{ax:viability}) is the only
objective: $|\phi| > 0$ (do not fall). The knife
(\cref{def:dissipation}) is the only regulariser:
$\gamma(e) \cdot c(e)$ (do not exceed limits).

Given a MuJoCo engine and a \texttt{.xml} model file, every step of
\cref{alg:loco} is mechanically executable.
The standing structure (\cref{rem:standing}) is read from the file.
The contact dynamics (\cref{sec:contact}) is computed by the engine.
The algorithm is the bridge.
\end{remark}

\begin{remark}[The policy as parallel transport]\label{rem:gauge}
In \cref{alg:loco}, the policy
$\pi \colon \R^{42+d} \to \R^{12}$
maps sensor readings to joint torques (\cref{def:observation}).
Unfolding $\pi$ as a neural network (\cref{def:neural-exgraph}):
\[
  o \;\xrightarrow{\;\textcolor{water}{\sigma_1 \circ W_1}\;}
  h_1 \;\xrightarrow{\;\textcolor{water}{\sigma_2 \circ W_2}\;}
  \cdots \;\xrightarrow{\;\textcolor{water}{\sigma_L \circ W_L}\;}
  \tau.
\]
Each arrow is a \textsc{Slide} (\S\ref{sec:calculus}, four operations):
the $(42\!+\!d)$-dimensional observation flows through $L$ layers,
each applying $\textcolor{water}{\sigma \circ W}$.
The composite is \textsc{Compose}: the forward pass.

This is parallel transport on the execution graph.
The weights $\{W_\ell\}_{\ell=1}^L$ define a \emph{connection}:
a rule for transporting observations through the network.
Different weights $=$ different connection.
Training (the \textcolor{water}{水} steps of \cref{alg:loco})
searches for the connection under which the transported
observation produces viable torques: $|\phi| > 0$.

The trained network is a fixed connection on the standing structure.
The spectral gap $\lambda_1 > 0$ (\cref{thm:massgap}) is its
stability: small perturbations in observation decay, not amplify.
\end{remark}

\begin{remark}[Frozen and learned connections]\label{rem:frozen-gauge}
The observation $o = (o_{\mathrm{prop}},\, o_{\mathrm{vis}})$
(\cref{def:observation}) passes through \emph{two} connections in
series:
\[
  \underbrace{I_{\mathrm{cam}}
  \;\xrightarrow{\;\varphi_{\mathrm{vis}}\;}
  o_{\mathrm{vis}}}_
  {\text{frozen (DINOv2)}}
  \;\oplus\;
  o_{\mathrm{prop}}
  \;\xrightarrow{\;\pi\;}
  \tau.
\]
The visual encoder $\varphi_{\mathrm{vis}}$ is a \emph{frozen
connection}: a pretrained ViT whose weights are fixed during
\cref{alg:loco}. It transports raw pixels into a semantic
embedding space. The policy $\pi$ is a \emph{learned connection}:
its weights are updated by the \textcolor{water}{水} steps.

In gauge-theoretic language: $\varphi_{\mathrm{vis}}$ is a
background gauge field (fixed geometry of the visual fibre bundle),
while $\pi$ is the dynamical gauge field (trained by the contact
gradient flow~\eqref{eq:contactflow}).
The visual encoder sees the terrain; the policy decides what to do
about it. Two connections, one frozen, one learned.
\end{remark}

\begin{remark}[Deployment: real-time frequency alignment]
\label{rem:deployment}
\Cref{alg:loco} trains in simulated time
($\Delta t = 0.02$\,s, control rate $50$\,Hz).
Deployment on real hardware requires the same loop at the same rate
in \emph{real} time:
\[
  \underbrace{o_t \leftarrow \texttt{sense}}_
  {\text{read sensors}}
  \;\to\;
  \underbrace{\tau_t \leftarrow \pi(o_t)}_
  {\text{evaluate NN}}
  \;\to\;
  \underbrace{q_{t+1} \leftarrow \texttt{actuate}(\tau_t)}_
  {\text{command joints}}
  \;\leq\; 20\,\text{ms}.
\]
The entire sense--compute--act cycle must complete within one
$\Delta t$. If the policy $\pi$ (the connection of
\cref{rem:gauge}) takes longer than $20$\,ms to evaluate, the
real-time constraint is violated: the flow is no longer at the
trained frequency, and viability is not guaranteed.

This is a viability condition on the computation itself.
The standing structure (\cref{rem:standing}) specifies the physical
constraints; the frequency constraint specifies the computational
one. Both must hold for deployment:
\[
  \underbrace{|\phi| > 0}_{\text{physics: do not fall}}
  \quad\wedge\quad
  \underbrace{t_{\pi} \leq \Delta t}_
  {\text{compute: do not lag}}.
\]
Time must be real and linear.
No simulation speedup, no frame drops.
\end{remark}

\begin{remark}[Annealing $\beta$ as renormalisation group flow]
\label{rem:rg-annealing}
The soft-min parameter $\beta$ (\cref{def:soft-viability}) anneals
with the curriculum (\cref{def:command}):
\[
  \text{Stand} \;(\beta \text{ small})
  \;\longrightarrow\;
  \text{Walk} \;(\beta \text{ medium})
  \;\longrightarrow\;
  \text{Work} \;(\beta \text{ large}).
\]
This is a renormalisation group (RG) flow from the ultraviolet
(UV, smooth, all-timestep gradient) to the infrared (IR, sharp,
worst-timestep gradient).
At small $\beta$, the viability margin is a soft average: the
gradient is dense and the optimisation landscape is smooth---the
robot learns to stand by distributing information across the
entire trajectory.
At large $\beta$, the margin approaches the hard $\min$: the
gradient concentrates on the single worst timestep---the robot
learns precise footwork by focusing on the critical instant.

The \textsc{Phase} operator ($\textcolor{sword}{\varphi}$) of the
calculus drives this flow.
Each phase transition $U_k \to U_{k+1}$ increases both the command
support and the sharpness $\beta$.
The contact gradient flow~\eqref{eq:contactflow} operates at the
current $\beta$; the curriculum selects the scale.
UV $\to$ IR: smooth $\to$ sharp, Stand $\to$ Work,
all-timestep $\to$ worst-timestep.
\end{remark}

\begin{definition}[Task RKHS (学堂)]\label{def:task-rkhs}
Let $\mathcal{T}$ be a set of tasks, each observed via a camera
image $I_\tau$.
The \emph{task kernel} is
\begin{equation}\label{eq:task-kernel}
  k(\tau_1, \tau_2)
  \;=\;
  \bigl\langle
  \varphi_{\mathrm{vis}}(I_{\tau_1}),\;\,
  \varphi_{\mathrm{vis}}(I_{\tau_2})
  \bigr\rangle_{\R^d},
\end{equation}
the inner product of DINOv2 embeddings
(\cref{def:observation}, $d = 384$).
The \emph{task RKHS} $\mathcal{H}_k$ is the reproducing kernel
Hilbert space induced by $k$: the space of skill functions
$f \colon \mathcal{T} \to \R^{12}$ with reproducing property
$f(\tau) = \langle f,\, k(\cdot, \tau) \rangle_{\mathcal{H}_k}$.

A \emph{demonstration} for task $\tau$ is a trajectory
$\mathcal{D}_\tau = \{(o_t,\, \tau_t^*)\}_{t=0}^{H}$
of observation--torque pairs, collected from a teacher
(teleoperation, motion capture, or a reference policy).
The \emph{task margin} at timestep $t$ is
\begin{equation}\label{eq:task-margin}
  m_{\mathrm{task}}(t)
  \;=\;
  \varepsilon_{\mathrm{task}}
  \;-\;
  \bigl\|\pi(o_t, u) - \tau_t^*\bigr\|,
\end{equation}
where $\varepsilon_{\mathrm{task}} > 0$ is the imitation
tolerance.
The Work-phase viability margin
extends~\eqref{eq:soft-viability}:
\begin{equation}\label{eq:work-margin}
  |\phi|_\beta^{\mathrm{Work}}
  \;=\;
  \mathrm{soft\text{-}min}_\beta\bigl(
  \underbrace{h(q_t) - h_{\min}}_{\text{height}},\;\;
  \underbrace{\phi_{\max} - \|R_t - I\|_F}_
  {\text{orientation}},\;\;
  \underbrace{\min_j z_j(q_t) - z_{\min}}_
  {\text{sinking}},\;\;
  \underbrace{m_{\mathrm{task}}(t)}_
  {\text{imitation}}
  \bigr)_{t=0}^{H}.
\end{equation}
During Stand and Walk, $\mathcal{D}_\tau = \varnothing$ and the
task term is absent ($e^{-\beta \cdot \infty} = 0$ in the
soft-min).
During Work, the demonstration is the teacher, and the kernel
$k$ provides generalisation: a policy trained on demonstrated
tasks $\{\tau_i\}$ transfers to a new task $\tau^*$ in proportion
to $k(\tau^*, \tau_i)$.
\end{definition}

\begin{remark}[The frozen eye as task metric]
\label{rem:task-metric}
The DINOv2 encoder $\varphi_{\mathrm{vis}}$
(\cref{def:observation}) serves two roles:
\begin{enumerate}[label=(\roman*)]
  \item \textbf{Observation}: maps camera images to
  $o_{\mathrm{vis}} \in \R^d$ for the policy
  (\cref{alg:forward}).
  \item \textbf{Task metric}: the kernel
  $k$~\eqref{eq:task-kernel} defines the geometry of the task
  space $\mathcal{T}$ (\cref{def:task-rkhs}).
\end{enumerate}
One encoder, two roles.
The differentiation boundary (\cref{rem:frozen-gauge}) is also
the metric boundary: the fixed geometry on which all tasks are
measured.

Because DINOv2 is pretrained on real images (ImageNet), the
kernel $k$ is anchored in reality, not simulation.
Tasks that look similar in the real world are close in
$\mathcal{H}_k$.
This bridges the sim-to-real gap for the Work phase:
a policy trained on task $\tau_1$ in simulation transfers to
a visually similar task $\tau_2$ in reality because
$k(\tau_1, \tau_2)$ is large.
The school (学堂) generalises through the kernel.
Demonstrations are lessons; the RKHS norm is the grade;
deployment is graduation.
\end{remark}

\begin{remark}[Hyperparameter atlas]\label{rem:hyperparameters}
\Cref{alg:loco} takes seven scalar hyperparameters.
They split into two tiers by origin.

\medskip
\noindent
\textbf{Tier 1: physics-determined}
(read from the engine or the task; not free choices).

\smallskip
{\small
\begin{center}
\begin{tabular}{@{}l l p{0.62\textwidth}@{}}
\toprule
Symbol & Source & Interpretation \\
\midrule
$\gamma$ &
  \texttt{XML} damping &
  Dissipation rate (thermodynamic 2nd law of the engine).
  Read from \texttt{go2\_mjx.xml}. \\
$H$ &
  Task duration &
  Horizon: timesteps per rollout.
  Typical: $500$--$2000$ (at $\Delta t$ of XML). \\
$\eta$ &
  Optimiser &
  Learning rate: the Planck scale of the update---the smallest
  step that moves $W$ meaningfully.
  $\eta \ll \gamma^{-1}$ ensures
  the flow~\eqref{eq:contactflow} is contractive.
  Typical: $10^{-4}$--$10^{-3}$. \\
\bottomrule
\end{tabular}
\end{center}
}

\smallskip
$\gamma$ is not a free knob: it is the physical dissipation
already baked into the simulator's contact model.
$H$ is set by the task (how long one episode lasts).
$\eta$ is fundamental: it converts the gradient $\nabla W$ into a
finite displacement, analogous to the Planck time converting
energy into frequency ($E = \hbar\omega$).
Too large $\Rightarrow$ instability; too small $\Rightarrow$
the agent never moves.

\medskip
\noindent
\textbf{Tier 2: user settings}
(design choices; tune on validation rollouts).

\smallskip
{\small
\begin{center}
\begin{tabular}{@{}l l p{0.62\textwidth}@{}}
\toprule
Symbol & Role & Interpretation \\
\midrule
$L$ &
  Depth &
  Number of layers in $\pi$ (\cref{alg:forward}).
  Typical: $3$--$5$. \\
$n$ &
  Width &
  Hidden dimension per layer.
  Typical: $128$--$512$. \\
$N$ &
  Eval count &
  Rollouts per gradient step (sample size for
  $|\phi|_\beta$).
  Typical: $64$--$4096$. \\
$\beta$ &
  Sharpness &
  RG scale (\cref{rem:rg-annealing}): small $\beta$ $=$ UV
  (smooth, exploratory); large $\beta$ $=$ IR (sharp,
  exploitative).
  Typical: $1$--$100$. \\
$\varepsilon_{\mathrm{task}}$ &
  Imitation &
  Task margin (\cref{def:task-rkhs});
  $\varnothing$ during Stand/Walk.
  Task-dependent. \\
\bottomrule
\end{tabular}
\end{center}
}

\smallskip
The tier boundary is sharp: Tier~1 parameters are
\emph{measured} (from the XML, the task, or the optimiser's
stability condition); Tier~2 parameters are
\emph{chosen} (by the user, validated by rollout performance).
A practitioner who changes the robot changes Tier~1;
a practitioner who changes the architecture changes Tier~2.
Neither tier crosses into the other.
\end{remark}

\begin{remark}[\textcolor{caution}{No tricks needed}]
\label{rem:no-tricks}
\Cref{alg:loco} is a policy gradient through a mollifier.
That is all.
We collect no replay buffer, fit no value function, clip no
surrogate objective, aggregate no datasets.

\medskip\noindent
\textbf{The engine is differentiable.}\;
MJX (the JAX backend of MuJoCo) provides
$\nabla_\tau \mathcal{E}.\texttt{step}$---the Jacobian of the
physics step with respect to torques.
This gradient is \emph{exact within a single contact mode}.
But locomotion is mode switching: every gait cycle crosses
$\geq 4$ contact boundaries (one per foot), and at each boundary
the contact Jacobian $J_c$ changes rank.
The engine gradient at a boundary is the left or right limit,
\emph{not} the gradient of the expected value.

\medskip\noindent
\textbf{We do not use the engine gradient.}\;
\Cref{alg:loco} treats $\mathcal{E}.\texttt{step}$ as a
\textcolor{knife}{black box}: the gradient does not penetrate
the physics.
The \textsc{Score} step (line~14) differentiates through the
policy $\pi_\theta$ only---never through $\mathcal{E}$.
The engine could be MuJoCo~C (non-differentiable),
MJX (differentiable), Brax, or real hardware.
The algorithm does not care.

\medskip\noindent
\textbf{The mollifier provides the gradient.}\;
The Student-$t$ policy (\cref{def:mollifier}) has full support
on $[-\bar\tau, \bar\tau]^{12}$ and is $C^\infty$ in $\theta$.
The expected viability
$\bar\phi(\theta) =
\mathbb{E}_{\pi_\theta}[|\phi|_\beta]$
is smooth in $\theta$---even though $|\phi|_\beta(\tau)$ is
non-smooth at contact boundaries---because integrating a
Lipschitz function against a smooth kernel with full support
produces a smooth function.
The Student-$t$ absorbs the contact discontinuity.

\medskip\noindent
\textbf{The remaining patches are still unnecessary:}
\begin{itemize}[leftmargin=*]
\item \textcolor{caution}{\textbf{DAgger}}: no distribution shift.
  Every rollout runs the current $\pi_\theta$ through the engine.
\item \textcolor{caution}{\textbf{PPO}}: no surrogate, no baseline,
  no clipping, no entropy bonus.
  The score function gives an unbiased gradient.
  The capacity clamp (\textsc{Clamp}) bounds $\|W_\ell\|_F$.
  Command sampling $u \sim U$ provides exploration.
\item \textcolor{caution}{\textbf{Value function}}: $|\phi|_\beta$
  is computed per-rollout, not estimated by a learned $V(s)$.
\end{itemize}

The pattern: every ``trick'' in model-free RL is a patch for a
missing gradient.
The Student-$t$ mollifier provides the gradient---through the
policy, not through the engine.
The patches become unnecessary.
\Cref{alg:loco} is not a new algorithm---it is what remains when
you \textcolor{caution}{delete the patches}.
\end{remark}

\section{Representation dynamics}\label{sec:representation}

The contact dynamics of \cref{sec:contact} trains a locomotion policy
on an execution graph with $12$ edges.
We now construct the dual of the agentic tower and show that the same
contact gradient flow, on different execution graphs, yields
text generation, image generation, and video generation as
instances of a single representation-learning paradigm.

\begin{definition}[Dual tower]\label{def:dual-tower}
The \emph{dual tower} of the agentic space
$\mathbf{L} = (L_0, L_1, L_2, L_3)$ (\cref{def:tower}) is
\[
  \mathbf{L}^*
  \;=\;
  \text{力}^* \;\oplus\; \text{立}^* \;\oplus\; \text{丽}^*,
\]
where:
\begin{enumerate}[label=\textbf{L\arabic*${}^*$}.]
  \item $\text{力}^* = L_0^*$:
  the dual of the state space.
  An element of $L_0^*$ is \emph{acted upon} physically:
  the medium as substrate (pixels, tokens, audio samples).
  \item $\text{立}^* = L_1^*$:
  the dual of the viable kernel.
  An element of $L_1^*$ is \emph{positioned} by external operations:
  structural coherence imposed (grammar, spatial consistency,
  temporal continuity).
  \item $\text{丽}^* = (L_2 \oplus L_3)^*$:
  the dual of the control-strategy bundle.
  An element of $(L_2 \oplus L_3)^*$ is \emph{represented} by
  the Subject's operations:
  meaning, style, and aesthetics as projected image.
\end{enumerate}
The three components are named by their Chinese homophones:
力~(force), 立~(stand), 丽~(beauty)---all pronounced~\emph{l\`\i}.
\end{definition}

The duality is grammatical: 力~acts, 力${}^*$~is acted upon.
立~stands, 立${}^*$~is positioned.
丽~creates beauty, 丽${}^*$~is made beautiful.
The operator~被 (passive voice marker) maps each component to its dual.

\begin{theorem}[Beauvoir representation]\label{thm:beauvoir}
The dual tower $\mathbf{L}^*$ is a faithful, irreducible
representation of the passive predicates on the agentic space.
Every predicate of the form ``$x$ is $f$-ed by~$b$'' for
$f \in \{\sigma, \partial, \circ, \varphi\}$ factors through
$\mathbf{L}^*$:
\begin{align*}
  \text{被}\,\sigma &\;\in\; \text{力}^*
    &&\text{(transported physically: 被恢复)}, \\
  \text{被}\,\partial &\;\in\; \text{立}^*
    &&\text{(cut / detected: 被看到)}, \\
  \text{被}\,\circ &\;\in\; \text{丽}^*
    &&\text{(composed into representation: 被表示)}, \\
  \text{被}\,\varphi &\;\in\; \text{丽}^*
    &&\text{(redefined by phase change: 被描述)}.
\end{align*}
\end{theorem}

\begin{proof}
The calculus is complete (\cref{prop:completeness}): every operation
on the agentic space decomposes into
$\{\sigma, \circ, \partial, \varphi\}$.
The dual of each operation is its passive form.
\textsc{Slide}~$\sigma$ is physical transport ($L_0$); its dual
被$\,\sigma$ acts on~$L_0^*$.
\textsc{Cut}~$\partial$ detects and removes ($L_1$: the boundary
of the viable kernel); its dual 被$\,\partial$ acts on~$L_1^*$.
\textsc{Compose}~$\circ$ and \textsc{Phase}~$\varphi$ build
representations and change regimes ($L_2 \oplus L_3$: control
and strategy); their duals act on~$(L_2 \oplus L_3)^*$.
By completeness, no predicate falls outside
$L_0^* \oplus L_1^* \oplus (L_2 \oplus L_3)^*$.
The decomposition is irreducible: removing any component removes
a calculus operation from the dual.
\end{proof}

\begin{theorem}[Camus absurdity]\label{thm:camus}
In any agentic space with knife dissipation $\gamma > 0$
(\cref{def:dissipation}), the absorbed energy at equilibrium
\[
  \mathcal{A}
  \;=\;
  \|z\| - |\phi|_{\mathrm{eq}}
  \;>\; 0.
\]
The flow deficit is strictly positive: the system always dissipates.
\end{theorem}

\begin{proof}
The contact gradient flow (\cref{def:contactflow}) reaches
equilibrium at $\partial|\phi|/\partial c(e) = \gamma(e)\,c(e)$
(\cref{thm:contactEL}).
The dissipation term $\gamma(e)\,c(e) > 0$ on bypass edges
prevents the capacities from reaching the flow-maximising assignment.
Therefore $|\phi|_{\mathrm{eq}} < \max|\phi| \leq \|z\|$ and
$\mathcal{A} > 0$.

The absorption is irreducible: setting $\gamma \to 0$ eliminates
dissipation but also eliminates the stability margin
$\lambda_1 > 0$ (\cref{rem:contact-stability}).
The system becomes unstable---small perturbations amplify rather
than decay.
The absurd is the price of stability.
\end{proof}

\begin{corollary}[Representation learning]\label{cor:replearn}
The contact gradient flow~\eqref{eq:contactflow} on the dual
tower $\mathbf{L}^*$ with objective $\mathcal{L} = -|\phi|$ is
representation learning:
\[
  \min_c \; \mathcal{A}(c)
  \quad\text{subject to}\quad
  c \in \mathbf{L}^*
  \;=\;
  \text{力}^* \oplus \text{立}^* \oplus \text{丽}^*.
\]
\cref{thm:beauvoir} identifies the representation space
($\mathbf{L}^*$).
\cref{thm:camus} identifies the objective ($\min \mathcal{A}$,
irreducible).
The contact gradient flow provides the dynamics.
\end{corollary}

\begin{definition}[Representation dynamics]\label{def:repdyn}
Let $G = (V, E, c)$ be an execution graph (\cref{def:exgraph}) on the
dual tower $\mathbf{L}^*$ (\cref{def:dual-tower}).
The \emph{representation dynamics} on $G$ is the contact gradient
flow~\eqref{eq:contactflow}:
\[
  \frac{dc(e)}{dt}
  \;=\;
  \frac{\partial|\phi|}{\partial c(e)}
  \;-\;
  \gamma(e)\,c(e),
  \qquad
  c(e) = \|W_e\|_F,
\]
where $|\phi|$ is the viability of the generated output
(\cref{cor:replearn}: $\mathcal{L} = -|\phi|$) and $\gamma$ is the
knife dissipation (\cref{def:dissipation}).
\end{definition}

\medskip
\noindent\fcolorbox{water}{water!5}{%
\begin{minipage}{\dimexpr\textwidth-2\fboxsep-2\fboxrule}
\smallskip
\textbf{\textcolor{water}{Why representation is contact dynamics.}}\;
The contact gradient flow~\eqref{eq:contactflow} is defined on any
execution graph with capacitated edges (\cref{def:exgraph}).
It does not distinguish whether the edges carry physical actuators
($c \in \mathbf{L}$) or neural weights
($c \in \mathbf{L}^*$).
Contact dynamics (\cref{sec:contact}) trains an agent to \emph{act}
(力\,立\,丽).
Representation dynamics trains a model to \emph{represent}
(力${}^*$\,立${}^*$\,丽${}^*$).
The operator~被 maps one to the other:
the same equation, the same flow, the same knife---on the dual tower.
\smallskip
\end{minipage}}
\medskip

\begin{remark}[Le Deuxi\`eme Sexe as tower]
\label{rem:beauvoir-tower}
Beauvoir's \emph{Le Deuxi\`eme Sexe}~\cite{beauvoir} is
structured as three parts that map to the dual tower:
\begin{center}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Volume~I Part} & \textbf{l\`\i} & \textbf{Tower} &
\textbf{Content} \\
\midrule
I.\ Destin (Destiny) & 力 & $L_0^*$ &
  Biology, body, physical substrate \\
II.\ Histoire (History) & 立 & $L_1^*$ &
  Social position, establishment \\
III.\ Mythes (Myths) & 丽 & $(L_2 \oplus L_3)^*$ &
  Cultural representation, image \\
\bottomrule
\end{tabular}
\end{center}
The historical examples of \cref{app:secondsex} (蔡文姬, 花木兰)
illustrate the tower: at every stage, the Other's identity
decomposes as 被力~$\oplus$~被立~$\oplus$~被丽---physically
acted upon, socially positioned, culturally represented.
The knife between Subject and Other is the mean
(\cref{thm:meanfield}): a phase function, not an intrinsic
property.
\end{remark}

\begin{definition}[Generation execution graph]\label{def:gen-exgraph}
A \emph{generation execution graph} is an execution graph
$G_{\mathrm{gen}} = (V, E, c)$ (\cref{def:exgraph}) where:
\begin{itemize}
  \item $\kappa$ is the conditioning input
  (prompt, noise schedule, or previous frames);
  \item $\infty$ is the generated output
  (tokens, pixels, or video frames);
  \item the intermediate nodes $\{a_i\}$ are the network layers;
  \item the capacity $c(e)$ is $\|W_e\|_F$
  (\cref{def:neural-exgraph}).
\end{itemize}
The viable flow condition $|\phi| > 0$ becomes: the
generated output is coherent.
\end{definition}

\begin{definition}[Representation model]\label{def:repmodel}
A \emph{representation model} is a family of maps
$\{f_m\}_{m \in \mathcal{M}}$ on modalities
$\mathcal{M} = \{\text{text},\, \text{image},\, \text{video}\}$,
sharing a backbone $g_\theta$ on the dual tower:
\[
  f_m \;=\; h_m \circ g_\theta \circ \tau_m,
  \qquad m \in \mathcal{M},
\]
where $\tau_m$ is a modality-specific tokeniser
(embed tokens / patchify pixels / patchify-and-stack frames)
and $h_m$ is a modality-specific head
(predict next token / denoise patches / denoise-and-predict frames).
The backbone $g_\theta$ operates on
$\mathbf{L}^* = \text{力}^* \oplus \text{立}^* \oplus \text{丽}^*$
(\cref{def:dual-tower}) and is shared across all modalities.
\end{definition}

\begin{algorithm}[H]
\caption{Contact-dynamics training for a representation model}
\label{alg:repmodel}
\begin{algorithmic}[1]
\Require Modality set
  $\mathcal{M} = \{\text{text},\, \text{image},\, \text{video}\}$
\Require For each $m \in \mathcal{M}$:\;
  graph $G_m$ (\cref{def:gen-exgraph}),\;
  dataset $\mathcal{D}_m$,\;
  tokeniser $\tau_m$
\Require $\eta$ (learning rate),\;
  $\gamma$ (dissipation),\;
  $\beta$ (soft-min sharpness),\;
  $L_s$ (backbone depth),\; $n$ (width),\;
  $N$ (eval count)
\Statex
\State \textbf{Backbone:}\;
  $\{W_\ell, b_\ell\}_{\ell=1}^{L_s}
  \leftarrow \texttt{init}(L_s,\, n)$
  \Comment{shared;\; $c(e_\ell) = \|W_\ell\|_F$}
\For{$m \in \mathcal{M}$}
  \Comment{modality-specific heads}
  \State $\{W_\ell^{m}, b_\ell^{m}\}_{\ell=1}^{L_m}
    \leftarrow \texttt{init}(L_m,\, n_m)$
\EndFor
\Statex
\For{\textcolor{sword}{\textbf{phase}} $\in$
  \{力\,$(U\!=\!\text{structure})$,\;\,
   立\,$(U\!=\!\text{coherence})$,\;\,
   丽\,$(U\!=\!\text{semantics})$\}}
  \Comment{\textcolor{sword}{$\varphi$: curriculum}}
  \Repeat
    \State $m \sim \mathrm{Unif}(\mathcal{M})$;\;\;
      $(z,\, x^*) \sim \mathcal{D}_m$
      \Comment{sample modality $+$ data}
    \State $\tilde{z} \leftarrow \tau_m(z)$
      \Comment{tokenise into $\mathbf{L}^*$}
    \State \textcolor{water}{\textsc{Forward}:}\;
      $\hat{x} \leftarrow h_m\bigl(g_\theta(\tilde{z})\bigr)$
      \Comment{\textcolor{water}{水: backbone $+$ head $m$}}
    \State \textcolor{water}{\textsc{Flow}:}\;
      $|\phi|_\beta^{(m)} \leftarrow
      \mathrm{soft\text{-}min}_\beta\bigl\{
      |\phi|_t^{(m)}
      \bigr\}_{t}$
      \Comment{\textcolor{water}{水: modality viability}}
    \State \textcolor{water}{\textsc{Backward}:}\;
      $\{\nabla W,\, \nabla b,\,
       \nabla W^{m},\, \nabla b^{m}\}
      \leftarrow \textsc{Backward}(\nabla_{\hat{x}}\, |\phi|_\beta^{(m)})$
      \Comment{\cref{alg:backward}}
    \State $W_\ell \leftarrow W_\ell
      + \eta\bigl[\textcolor{water}{\nabla W_\ell}
      - \textcolor{knife}{\gamma\, W_\ell}\bigr]$;\;\;
      $b_\ell \leftarrow b_\ell
      + \eta\,\textcolor{water}{\nabla b_\ell}$
      \Comment{backbone: Eq.~\eqref{eq:contactflow}}
    \State $W_\ell^{m} \leftarrow W_\ell^{m}
      + \eta\bigl[\textcolor{water}{\nabla W_\ell^{m}}
      - \textcolor{knife}{\gamma\, W_\ell^{m}}\bigr]$;\;\;
      $b_\ell^{m} \leftarrow b_\ell^{m}
      + \eta\,\textcolor{water}{\nabla b_\ell^{m}}$
      \Comment{head $m$: Eq.~\eqref{eq:contactflow}}
    \State \textcolor{knife}{\textsc{Clamp}:}\;
      $\|W_\ell\|_F \leftarrow
      \min\bigl(\|W_\ell\|_F,\;
      c_{\max}(e_\ell)\bigr)$
      for all $\ell$
      \Comment{\textcolor{knife}{刀: capacity}}
    \If{$|\phi|_\beta^{(m)} \le 0$}
      \Comment{output incoherent in modality $m$}
      \State \textcolor{sword}{\textsc{Reset}:}\;
        head only: $\{W^m, b^m\} \leftarrow \texttt{init}(L_m, n_m)$
        \Comment{\textcolor{sword}{$\varphi$: recover modality}}
    \EndIf
  \Until{$\forall\, m\!:\; \max|\phi|^{(m)} = \min|C^{(m)}|$
    for $N$ consecutive evaluations}
\EndFor
\Statex
\Ensure Representation model:
  $f_m = h_m \circ g_\theta \circ \tau_m$
  for all $m \in \mathcal{M}$,
  backbone on $\mathbf{L}^*$
\end{algorithmic}
\end{algorithm}

\begin{remark}[Three bodies, one backbone]
\label{rem:repmodel-bodies}
The modality-specific components of \cref{alg:repmodel} are:
\begin{center}
\small
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{@{}l lll@{}}
\toprule
& \textbf{Text} & \textbf{Image} & \textbf{Video} \\
\midrule
$G_m$ (topology)
  & sequential & 2D patches & 2D patches $\times\, T$ \\
$\kappa_m$ (input)
  & context tokens & noise $+$ prompt
  & noise $+$ prompt $+$ prev.\ frames \\
$\tau_m$ (tokeniser)
  & BPE embedding & patchify $+$ linear
  & patchify $+$ linear $+$ temporal \\
$h_m$ (head)
  & softmax over $V$ & depatchify to $\R^{H \times W \times 3}$
  & depatchify $\times\, T$ \\
$|\phi|^{(m)}$ (viability)
  & $\log p(x_t^* \mid x_{<t})$
  & $\varepsilon - \|\hat{x} - x^*\|$
  & $\min(\text{spatial},\; \lambda_T \!\cdot\! \text{temporal})$ \\
$\gamma^{(m)}$ (knife)
  & weight decay & guidance scale
  & temporal regularisation \\
\textsc{Phase}
  & char $\to$ word $\to$ doc
  & noise $\to$ coarse $\to$ fine
  & frame $\to$ clip $\to$ video \\
\bottomrule
\end{tabular}
\end{center}
The backbone $g_\theta$ sees none of these distinctions.
It operates on $\mathbf{L}^*$: medium tokens (力${}^*$),
structural coherence (立${}^*$), semantic content (丽${}^*$).
The modality is invisible at the representation level---this is
why a single backbone suffices.
\end{remark}

\begin{remark}[Representation model $=$ locomotion on every body]
\label{rem:repmodel-loco}
Compare \cref{alg:repmodel} with \cref{alg:loco}:
\begin{center}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{@{}lll@{}}
\toprule
& \textbf{Locomotion (\cref{alg:loco})} &
\textbf{Representation model (\cref{alg:repmodel})} \\
\midrule
Body & quadruped ($12$ joints) &
  text / image / video \\
Standing & $h > h_{\min}$ (do not fall) &
  $|\phi|^{(m)} > 0$ (stay coherent) \\
Engine & MuJoCo (physics) &
  autodiff (shared backbone $g_\theta$) \\
Knife & joint limits ($c_{\max}$) &
  capacity bounds ($c_{\max}$) \\
Curriculum & Stand $\to$ Walk $\to$ Work &
  力 $\to$ 立 $\to$ 丽 \\
\bottomrule
\end{tabular}
\end{center}
A robot that falls is a text that is incoherent is an image that is
noise is a video that flickers.
The contact gradient flow is the same.
The body is different.
The representation model learns all bodies at once---三位一体:
one backbone on $\mathbf{L}^*$, three modalities, one gradient flow.
\end{remark}

\begin{remark}[LoRA $=$ low-rank task head]
\label{rem:lora}
Low-Rank Adaptation (LoRA) is a task head in the sense of
\cref{def:repmodel}.
Given a pre-trained backbone with layer weights
$\{W_\ell\}_{\ell=1}^L$, a LoRA adapter of rank~$r$ adds
\[
  \Delta W_\ell \;=\; B_\ell\, A_\ell,
  \qquad B_\ell \in \R^{d \times r},\;\;
  A_\ell \in \R^{r \times d},\;\;
  r \ll d,
\]
at each layer.
The backbone $W_\ell$ is frozen; the adapter $\Delta W_\ell$ is trained.
In the dual tower:
$W_\ell$ is the representation ($\mathbf{L}^*$),
$\Delta W_\ell$ is the task function
($\mathcal{H}_{\mathcal{T}}$, \cref{def:task-rkhs}),
and the rank~$r = c_{\max}(e_\ell^{\mathrm{task}})$ is the knife---it
bounds how far the task can deviate from the representation.
\end{remark}

\begin{definition}[Code metric space]
\label{def:code-metric}
The \emph{code metric space} is the agentic tower
(\cref{def:tower}) unbundled to four levels, each equipped with
a viability metric.
The general dual tower compresses
$L_2^* \oplus L_3^* \to \text{丽}^*$;
the code metric space resolves them into correctness ($L_2^*$)
and performance ($L_3^*$), yielding four phases---力, 立, 丽(正), 丽(快).
Correctness and performance are both sub-types of
丽~(value)---all three characters pronounced \emph{l\`\i}:
\begin{itemize}
  \item $\phi_{\mathrm{topo}}$ (\textbf{力${}^*$}, data topology,
  指针序):\;
  source forms a valid abstract syntax tree, all imports resolve,
  all names are bound.
  The data-structure graph (pointer\,/\,reference topology) is
  well-formed.
  Binary: $\phi_{\mathrm{topo}} \in \{0,\, 1\}$.

  \item $\phi_{\mathrm{safe}}$ (\textbf{立${}^*$}, memory safety,
  内存安全):\;
  program executes without crashing---no segmentation fault,
  no uncaught exception, no resource leak, no use-after-free.
  Binary: $\phi_{\mathrm{safe}} \in \{0,\, 1\}$.

  \item $\phi_{\mathrm{correct}}$ (\textbf{丽(正)${}^*$}, correctness,
  正确):\;
  output matches specification---all assertions hold, all tests pass.
  Ratio: $\phi_{\mathrm{correct}} =
  \text{tests passed}\,/\,\text{tests total} \in [0,\, 1]$.

  \item $\phi_{\mathrm{perf}}$ (\textbf{丽(快)${}^*$}, performance,
  快):\;
  program completes within time and space budgets.
  Continuous: $\phi_{\mathrm{perf}} =
  \max\!\bigl(0,\; 1 - t_{\mathrm{run}} / t_{\mathrm{budget}}\bigr)
  \in [0,\, 1]$.
\end{itemize}
The ordering is a prerequisite chain (each gates the next):
\[
  \phi_{\mathrm{topo}} \;\to\;
  \phi_{\mathrm{safe}} \;\to\;
  \phi_{\mathrm{correct}} \;\to\;
  \phi_{\mathrm{perf}}.
\]
You cannot profile code that crashes;
you cannot test code that does not parse.
The combined viability is
\[
  |\phi|_{\mathrm{code}} \;=\;
  \mathrm{soft\text{-}min}_\beta\bigl\{
  \phi_{\mathrm{topo}},\;
  \phi_{\mathrm{safe}},\;
  \phi_{\mathrm{correct}},\;
  \phi_{\mathrm{perf}}
  \bigr\}.
\]
Every programming language has all four levels.
Languages differ in which levels are enforced automatically:
\begin{center}
\renewcommand{\arraystretch}{1.25}
\resizebox{\linewidth}{!}{%
\begin{tabular}{@{}l llll@{}}
\toprule
\textbf{Language}
  & \textbf{力 (topo)} & \textbf{立 (safe)}
  & \textbf{丽(正) (correct)} & \textbf{丽(快) (perf)} \\
\midrule
Python
  & \texttt{ast.parse()}
  & \texttt{python f.py} exits $0$
  & \texttt{pytest} passes
  & \texttt{timeit} $\leq$ budget \\
C
  & \texttt{gcc -fsyntax-only}
  & Valgrind: no errors
  & tests pass
  & \texttt{perf stat} $\leq$ budget \\
Rust
  & \texttt{cargo check}
  & borrow checker (compile-time!)
  & \texttt{cargo test}
  & \texttt{cargo bench} $\leq$ budget \\
CUDA
  & \texttt{nvcc -c}
  & \texttt{compute-sanitizer}: 0 errors
  & trajectory converges
  & \texttt{nsight} $\leq$ budget \\
\bottomrule
\end{tabular}}%
\end{center}
\end{definition}

Fine-tuning is representation dynamics at school.
The representation model (\cref{def:repmodel}) learns $\mathbf{L}^*$
from mixed-modality data (\cref{alg:repmodel}).
Fine-tuning attaches a LoRA adapter (\cref{rem:lora}) to the frozen
backbone and trains it on task-specific data in the 学堂
(\cref{def:task-rkhs}).
For code generation, the code metric space (\cref{def:code-metric})
provides four viability metrics trained in prerequisite order.
\Cref{alg:finetune} is self-contained: an ML engineer with a
pre-trained checkpoint, a GPU server, a sandbox, and the four
viability metrics can execute it directly.

\begin{algorithm}[H]
\caption{Fine-tuning a representation model (学堂)}
\label{alg:finetune}
\begin{algorithmic}[1]
\Require Checkpoint $\theta_0$
  (e.g.\ \texttt{deepseek-coder-v2});\;
  tokenizer $\tau$;\;
  GPU server $\mathcal{E}_{\mathrm{GPU}}$
\Require Sandbox $\mathcal{E}_{\mathrm{sandbox}}$
  (e.g.\ Docker, \texttt{venv}, \texttt{nsjail})
\Require Task $\mathcal{T}$:\;
  dataset $\mathcal{D} = \{(z_i, x_i^*)\}$ (Q-A mode)
  or judge $J$ (court mode)
\Require Viability metrics
  $\phi_1 \to \cdots \to \phi_K$
  in prerequisite order
  (\cref{def:code-metric}: $K\!=\!4$)
\Require $r$ (LoRA rank $=$ knife),\;
  $\alpha$ (LoRA scaling),\;
  $\eta$ (learning rate),\;
  $\gamma$ (weight decay),\;
  $\beta$ (soft-min sharpness),\;
  $N$ (eval count)
\Statex
\State $\{W_\ell\}_{\ell=1}^{L}
  \leftarrow \texttt{load}(\theta_0)$;\;\;
  \texttt{freeze}($W$)
  \Comment{backbone on $\mathbf{L}^*$: frozen}
\State $\{B_\ell \!=\! 0,\;
  A_\ell \!\sim\! \mathcal{N}(0, \sigma^2)
  \}_{\ell=1}^{L}$
  \Comment{LoRA init: $\Delta W_\ell = B_\ell A_\ell = 0$}
\Statex
\For{\textcolor{sword}{\textbf{phase}} $\in$
  \{力\,$(\phi_{\mathrm{topo}})$,\;\,
   立\,$(\phi_{\mathrm{safe}})$,\;\,
   丽(正)\,$(\phi_{\mathrm{correct}})$,\;\,
   丽(快)\,$(\phi_{\mathrm{perf}})$\}}
  \Comment{\textcolor{sword}{$\varphi$: curriculum (\cref{def:code-metric})}}
  \Repeat
    \State $(z,\, x^*) \sim \mathcal{D}$\; or\; $z \sim \mathcal{T}$
      \Comment{Q-A: input $+$ target;\; court: input only}
    \State \textcolor{water}{\textsc{Forward}:}\;
      $\hat{x} \leftarrow \textsc{Forward}\bigl(\tau(z);\;
      \{W_\ell + \tfrac{\alpha}{r}\,
      \textcolor{water}{B_\ell A_\ell}\}\bigr)$
      \Comment{\cref{alg:forward}; backbone $+$ adapter}
    \State \textcolor{water}{\textsc{Execute}:}\;
      $\mathrm{result} \leftarrow
      \mathcal{E}_{\mathrm{sandbox}}.\texttt{run}(\hat{x})$
      \Comment{\textcolor{water}{水:} run generated code in sandbox}
    \State \textcolor{water}{\textsc{Evaluate}:}\;
      $|\phi|_\beta \leftarrow
      \mathrm{soft\text{-}min}_\beta\bigl\{
      \phi_k(\mathrm{result}_t)
      \bigr\}_{t}$
      \Comment{\textcolor{water}{水:} phase-$k$ metric
      (\cref{def:code-metric})}
    \State \textcolor{water}{\textsc{Backward}:}\;
      $\{\nabla B_\ell,\, \nabla A_\ell\}_{\ell=1}^{L}
      \leftarrow \textsc{Backward}(\nabla_{\hat{x}}\,
      |\phi|_\beta)$
      \Comment{\cref{alg:backward};\; $W$ frozen}
    \State $B_\ell \leftarrow B_\ell
      + \eta\,\textcolor{water}{\nabla B_\ell}$;\;\;
      $A_\ell \leftarrow A_\ell
      + \eta\bigl[\textcolor{water}{\nabla A_\ell}
      - \textcolor{knife}{\gamma\, A_\ell}\bigr]$
      \Comment{Eq.~\eqref{eq:contactflow} on adapter}
    \State \textcolor{knife}{\textsc{Clamp}:}\;
      $\|B_\ell A_\ell\|_F \leftarrow
      \min\bigl(\|B_\ell A_\ell\|_F,\;
      c_{\max}\bigr)$
      \Comment{\textcolor{knife}{刀: adapter capacity}}
    \If{$|\phi|_\beta \le 0$}
      \Comment{output incoherent}
      \State \textcolor{sword}{\textsc{Reset}:}\;
        $B_\ell \leftarrow 0$;\;
        $A_\ell \sim \mathcal{N}(0, \sigma^2)$
        \Comment{\textcolor{sword}{$\varphi$: re-init adapter}}
    \EndIf
  \Until{$\max|\phi| = \min|C|$ for $N$ consecutive evaluations}
\EndFor
\Statex
\Ensure Adapted model:\;
  $W_\ell^{\mathrm{out}} = W_\ell
  + \tfrac{\alpha}{r}\,B_\ell A_\ell$;\;\;
  \texttt{merge\_and\_upload}
\end{algorithmic}
\end{algorithm}

\begin{figure}[H]
\centering
\begin{tikzpicture}[
  >=stealth,
  box/.style={draw, rounded corners=2pt, minimum width=5.2cm,
              minimum height=0.55cm, align=center, font=\small},
  io/.style={box, fill=black!5},
  wt/.style={box, fill=water!10},
  arr/.style={->, thick, black!60},
]
\node[io] (init) at (0,0)
  {Checkpoint $\theta_0$;\;\;\texttt{freeze}($W$);\;\;init LoRA};
\node[draw, fill=sword!12, rounded corners=2pt,
  font=\small\bfseries, minimum width=5.2cm,
  minimum height=0.5cm, align=center] (phase) at (0,-1.0)
  {\textcolor{sword}{$\varphi$:}\;
   力 $\to$ 立 $\to$ 丽(正) $\to$ 丽(快)};
\node[wt] (fwd)  at (0,-2.1)
  {\textcolor{water}{\textsc{Forward}}:\;
   $\hat{x} = f\!\bigl(\tau(z);\;W\!+\!\tfrac{\alpha}{r}BA\bigr)$};
\node[wt] (exec) at (0,-2.9)
  {\textcolor{water}{\textsc{Execute}}:\;
   sandbox.\texttt{run}($\hat{x}$)};
\node[wt] (eval) at (0,-3.7)
  {\textcolor{water}{\textsc{Evaluate}}:\;
   $|\phi|_\beta = \mathrm{soft\text{-}min}\{\phi_k\}$};
\node[wt] (bwd)  at (0,-4.5)
  {\textcolor{water}{\textsc{Backward}}:\;
   $\nabla B,\,\nabla A$\;($W$ frozen)};
\node[wt] (upd)  at (0,-5.3)
  {\textsc{Update}:\;Eq.~\eqref{eq:contactflow} on $B,A$;\;\;
   \textcolor{knife}{\textsc{Clamp}}};
\node[io] (merge) at (0,-6.5)
  {Merge:\;$W^{\mathrm{out}} = W + \tfrac{\alpha}{r}BA$;\;\;
   \texttt{upload}};
\draw[arr] (init)  -- (phase);
\draw[arr] (phase) -- (fwd);
\draw[arr] (fwd)   -- (exec);
\draw[arr] (exec)  -- (eval);
\draw[arr] (eval)  -- (bwd);
\draw[arr] (bwd)   -- (upd);
\draw[arr] (upd)   -- node[right,font=\scriptsize]{converged} (merge);
\draw[arr, knife]  (upd.east) -- ++(1.3,0) |-
  node[right, pos=0.25, font=\scriptsize, color=knife]{repeat}
  (fwd.east);
\draw[dashed, rounded corners=3pt, black!25]
  (-3.0,-1.7) rectangle (3.5,-5.65);
\node[font=\tiny, black!40, anchor=south east]
  at (3.5,-1.7) {per phase};
\end{tikzpicture}
\caption{Fine-tuning pipeline (\cref{alg:finetune}).
  Outer loop: four-phase curriculum
  (力~$\to$~立~$\to$~丽(正)~$\to$~丽(快)).
  Inner loop: contact gradient
  flow~\eqref{eq:contactflow} on the LoRA adapter.}
\label{fig:finetune-flow}
\end{figure}

\begin{remark}[Validation chain: checkpoint $+$ sandbox $+$ metrics
$\Rightarrow$ coder]
\label{rem:finetune-chain}
Every input to \cref{alg:finetune} is extracted from four artifacts:
a pre-trained checkpoint, a code sandbox, a task dataset (or judge),
and user-defined viability metrics (\cref{def:code-metric}).
No additional assumptions.
\begin{center}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Algorithm input} & \textbf{Source} & \textbf{Extraction} \\
\midrule
Backbone $\{W_\ell\}$ ($L$ layers)
  & Checkpoint & \texttt{model.safetensors} \\
Tokenizer $\tau$
  & Checkpoint & \texttt{tokenizer.json} \\
Architecture ($d$, $L$, heads)
  & Checkpoint & \texttt{config.json} \\
LoRA rank $r$, scaling $\alpha$
  & User & Capacity budget ($r = 16$ typical) \\
Task data $\mathcal{D}$ or judge $J$
  & User & Q-A pairs or LLM evaluator \\
$\phi_{\mathrm{topo}},\, \phi_{\mathrm{safe}},\,
\phi_{\mathrm{correct}},\, \phi_{\mathrm{perf}}$
  & User & Viability metrics (\cref{def:code-metric}) \\
Code execution
  & Sandbox & Docker\,/\,\texttt{venv}\,/\,\texttt{nsjail} \\
Gradient $\nabla_{\hat{x}} |\phi|$
  & GPU server & Autodiff (PyTorch\,/\,JAX) \\
\bottomrule
\end{tabular}
\end{center}
The four-phase curriculum parallels the locomotion curriculum
(\cref{alg:loco})---with one refinement: 丽${}^*$ unbundles
into correctness ($L_2^*$) and performance ($L_3^*$):
\begin{center}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{@{}lllll@{}}
\toprule
\textbf{Phase} & \textbf{Tower} & \textbf{Locomotion} &
\textbf{Fine-tuning} & \textbf{Coding} \\
\midrule
力 & $L_0^*$ & $h > h_{\min}$ (don't fall)
  & $\phi_{\mathrm{topo}} > 0$ & AST valid \\
立 & $L_1^*$ & stable gait
  & $\phi_{\mathrm{safe}} > 0$ & no crash \\
丽(正) & $L_2^*$ & reach target
  & $\phi_{\mathrm{correct}} > 0$ & tests pass \\
丽(快) & $L_3^*$ & energy-efficient
  & $\phi_{\mathrm{perf}} > 0$ & within budget \\
\bottomrule
\end{tabular}
\end{center}
A robot that falls is code that does not parse.
A robot that stumbles is code that crashes.
A robot that walks is code that passes its tests.
A robot that runs is code that runs fast.

Two evaluation modes (\cref{def:task-rkhs}):
\begin{center}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{@{}lll@{}}
\toprule
& \textbf{Q-A mode} & \textbf{Court mode} \\
\midrule
Data & $(z, x^*)$ pairs & inputs $z$ only \\
$|\phi|$ & $\varepsilon - \|\hat{x} - x^*\|$ & $J(z, \hat{x})$ \\
Judge & ground truth & LLM evaluator \\
Use & code with test suite & open-ended generation \\
\bottomrule
\end{tabular}
\end{center}
Given a checkpoint, a sandbox, a task dataset, and four viability
metrics, every step of \cref{alg:finetune} is mechanically executable.
The model already knows $\mathbf{L}^*$.
School teaches it the task---力, 立, 丽(正), 丽(快)---four phases, one flow.
\end{remark}

\begin{remark}[CUDA TrajOpt: the loop closes]
\label{rem:cuda-loop}
Add CUDA to the language table (\cref{def:code-metric}):
\texttt{nvcc} compiles (力),
\texttt{compute-sanitizer} catches memory errors (立),
the trajectory converges (丽(正)),
the kernel meets its real-time budget (丽(快)).
The fine-tuned coder (\cref{alg:finetune}) writes
CUDA trajectory-optimisation kernels.
These kernels solve the same contact gradient
flow~\eqref{eq:contactflow} that trained the coder---on a physical
body instead of a token sequence.
The contact gradient flow appears at every level:
\begin{enumerate}
  \item \emph{Representation model} (\cref{alg:repmodel}):
  backbone $g_\theta$ learns $\mathbf{L}^*$ from mixed-modality data.
  \item \emph{Fine-tuning} (\cref{alg:finetune}):
  LoRA adapter learns the coding task on $\mathbf{L}^*$.
  \item \emph{Locomotion} (\cref{alg:loco}):
  the CUDA kernel output by the fine-tuned model
  controls the robot via the same flow.
\end{enumerate}
Level~2 produces the code that implements level~3.
The equation writes itself.
\end{remark}

\begin{remark}[For ML engineers: there is no ``agent'']
\label{rem:no-agent}
You do not train an \emph{agent}.
You train a model to produce
\textcolor{water}{perfect code}---one piece at a time.

Each piece must pass four gates in prerequisite order:
\begin{enumerate}
  \item[\textcolor{sword}{力}] It \textbf{parses}.
  \quad $\phi_{\mathrm{topo}} = 1$.\quad
  \textcolor{knife}{Fail $\Rightarrow$ \textsc{Reset}}.
  \item[\textcolor{sword}{立}] It \textbf{runs}.
  \quad $\phi_{\mathrm{safe}} = 1$.\quad
  \textcolor{knife}{Crash $\Rightarrow$ \textsc{Reset}}.
  \item[\textcolor{sword}{丽\textsuperscript{正}}] It is \textbf{correct}.
  \quad $\phi_{\mathrm{correct}} \in [0,1]$.\quad
  \textcolor{knife}{Wrong output $\Rightarrow$ gradient}.
  \item[\textcolor{sword}{丽\textsuperscript{快}}] It is \textbf{fast}.
  \quad $\phi_{\mathrm{perf}} \in [0,1]$.\quad
  \textcolor{knife}{Too slow $\Rightarrow$ gradient}.
\end{enumerate}
A piece that fails gates 1--2 is
\textcolor{knife}{killed}: $|\phi|_\beta \leq 0
\;\Rightarrow\;$\textcolor{knife}{\textsc{Reset}}
(\cref{alg:finetune}, line~13).
A piece that passes all four is
\textcolor{water}{viable}: $|\phi|_\beta > 0$.

The dataset is not dialogues.
Not trajectories.
Not reward signals.
It is \textcolor{water}{$(z, x^*)$ pairs}:
$z$ is a specification, $x^*$ is code that satisfies it.
Court mode (\cref{def:task-rkhs}):
a judge $J(z, \hat{x})$ replaces $x^*$ when ground truth is
unavailable.

There is no reinforcement learning in \cref{alg:finetune}.
There is no reward model.
There is a \textcolor{water}{flow}~\eqref{eq:contactflow},
a \textcolor{knife}{knife} ($\gamma > 0$),
and a \textcolor{sword}{curriculum}
(力~$\to$~立~$\to$~丽(正)~$\to$~丽(快)).
The training loop is supervised:
\textcolor{water}{forward},
\textcolor{water}{evaluate},
\textcolor{water}{backward},
\textcolor{knife}{clamp}.
Four words.
The ``agent'' is what happens \emph{after} training,
when the model generates
\textcolor{water}{enough viable code} to solve a task
that no single piece covers.
That is \textcolor{water}{composition~($\circ$)}, not training.
Training produces pieces.
Composition produces agents.
\end{remark}

\begin{algorithm}[H]
\caption{Code evaluation --- the judge protocol}
\label{alg:code-eval}
\begin{algorithmic}[1]
\Require Specification $z$ (natural language or formal)
\Require Generated code $\hat{x}$
  (output of \cref{alg:finetune})
\Require Sandbox $\mathcal{E}_{\mathrm{sandbox}}$;\;
  time budget $t_{\mathrm{budget}}$
\Require Judge $J$ (external LLM, e.g.\ Gemini-Pro ---
  \emph{must differ from generator})
\Statex
\State \textcolor{sword}{\textbf{Gate\;力}}
  (automated, \textcolor{water}{0 API calls}):
\State \quad $\phi_{\mathrm{topo}} \leftarrow
  \mathbf{1}\bigl[\texttt{parse}(\hat{x})\;\text{succeeds}\bigr]$
  \Comment{compiler / \texttt{ast.parse} / \texttt{nvcc -c}}
\If{$\phi_{\mathrm{topo}} = 0$}
  \textcolor{knife}{\Return} $|\phi|_{\mathrm{code}} = 0$
  \Comment{\textcolor{knife}{killed}: does not parse}
\EndIf
\Statex
\State \textcolor{sword}{\textbf{Gate\;立}}
  (automated, \textcolor{water}{0 API calls}):
\State \quad $(\mathrm{result},\; t_{\mathrm{run}}) \leftarrow
  \mathcal{E}_{\mathrm{sandbox}}.\texttt{run}(
  \hat{x},\; t_{\mathrm{budget}})$
\State \quad $\phi_{\mathrm{safe}} \leftarrow
  \mathbf{1}\bigl[\text{exit code} = 0\bigr]$
  \Comment{no crash, no leak, no timeout}
\If{$\phi_{\mathrm{safe}} = 0$}
  \textcolor{knife}{\Return} $|\phi|_{\mathrm{code}} = 0$
  \Comment{\textcolor{knife}{killed}: runtime crash}
\EndIf
\Statex
\State \textcolor{sword}{\textbf{Gate\;丽(正)}}
  (judge, \textcolor{caution}{1 API call}):
\State \quad $\phi_{\mathrm{correct}} \leftarrow
  J\!\bigl(z,\;\hat{x},\;\mathrm{result}\bigr)
  \;\in [0,1]$
  \Comment{``does output satisfy spec $z$?''}
\Statex
\State \textcolor{sword}{\textbf{Gate\;丽(快)}}
  (profiler, \textcolor{water}{0 API calls}):
\State \quad $\phi_{\mathrm{perf}} \leftarrow
  \max\!\bigl(0,\;\, 1 - t_{\mathrm{run}}\,/\,
  t_{\mathrm{budget}}\bigr)$
  \Comment{wall-clock; no judge needed}
\Statex
\State \textcolor{water}{$|\phi|_{\mathrm{code}}$} $\leftarrow
  \mathrm{soft\text{-}min}_\beta\bigl\{
  \phi_{\mathrm{topo}},\;
  \phi_{\mathrm{safe}},\;
  \phi_{\mathrm{correct}},\;
  \phi_{\mathrm{perf}}\bigr\}$
  \Comment{\cref{def:code-metric}}
\Statex
\Ensure \textcolor{water}{$|\phi|_{\mathrm{code}} \in [0,1]$}:\;
  plug into \cref{alg:finetune}, line~8
\end{algorithmic}
\end{algorithm}

\begin{remark}[The judge is not the teacher]
\label{rem:judge}
The judge $J$ in \cref{alg:code-eval} is \emph{not} the generator.
If \textcolor{water}{DeepSeek} generates, \textcolor{caution}{Gemini}
evaluates.
If \textcolor{water}{Gemini} generates, \textcolor{caution}{DeepSeek}
evaluates.
The adversarial independence is structural:
the court (\cref{def:task-rkhs}) requires a judge
who did not write the code.

The prerequisite chain saves money.
Gates \textcolor{sword}{力} and \textcolor{sword}{立} are
\textcolor{water}{free}:
compilers and sandboxes cost \textcolor{water}{zero} API calls.
Code that does not parse or crashes is
\textcolor{knife}{killed} before the judge sees it.
Only code that parses \emph{and} runs reaches
Gate~\textcolor{sword}{丽(正)}---\textcolor{caution}{one API call}
per surviving piece.
Gate~\textcolor{sword}{丽(快)} is the profiler:
wall-clock time does not require a judge.

The cost structure:
\begin{center}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Gate} & \textbf{Checker} & \textbf{Cost} &
\textbf{Kills} \\
\midrule
\textcolor{sword}{力} & compiler / parser
  & \textcolor{water}{0 API calls}
  & syntax errors \\
\textcolor{sword}{立} & sandbox
  & \textcolor{water}{0 API calls}
  & crashes, leaks, timeouts \\
\textcolor{sword}{丽(正)} & judge $J$
  & \textcolor{caution}{1 API call}
  & wrong output \\
\textcolor{sword}{丽(快)} & profiler
  & \textcolor{water}{0 API calls}
  & slow code \\
\bottomrule
\end{tabular}
\end{center}
The engineer provides the specification $z$.
The compiler checks \textcolor{sword}{力}.
The sandbox checks \textcolor{sword}{立}.
The judge checks \textcolor{sword}{丽(正)}.
The profiler checks \textcolor{sword}{丽(快)}.
The engineer does not need to know what perfect code looks like.
The \textcolor{water}{pipeline} knows.
\end{remark}

\begin{algorithm}[H]
\caption{Sandbox execution --- the physics engine for code}
\label{alg:sandbox}
\begin{algorithmic}[1]
\Require Generated code $\hat{x}$
  (from \cref{alg:finetune}, line~6)
\Require Resource limits:\;
  $t_{\max}$ (time),\; $m_{\max}$ (memory),\;
  syscall whitelist $\mathcal{S}$
\Require Runtime: Docker, \texttt{nsjail}, or \texttt{venv}
\Statex
\State \textcolor{sword}{\textsc{Build}}:\;
  $\mathcal{C} \leftarrow \texttt{container.create}\bigl(
  \mathrm{image},\;
  t_{\max},\;
  m_{\max},\;
  \texttt{net=none},\;
  \texttt{fs=read\text{-}only},\;
  \mathcal{S}\bigr)$
  \Comment{isolated jail}
\State \textcolor{water}{\textsc{Inject}}:\;
  $\texttt{write}\bigl(
  \mathcal{C}\texttt{:/sandbox/main},\;
  \hat{x}\bigr)$
  \Comment{code $\to$ sandbox}
\State \textcolor{water}{\textsc{Execute}}:\;
  $(\texttt{stdout},\;\texttt{stderr},\;
  \texttt{exit\_code},\;t_{\mathrm{run}})
  \leftarrow \mathcal{C}.\texttt{run}\bigl(
  \texttt{/sandbox/main},\;
  t_{\max}\bigr)$
  \Comment{run with limits}
\State \textcolor{water}{\textsc{Extract}}:\;
  $\mathrm{result} \leftarrow
  \texttt{parse}(\texttt{stdout})$;\;\;
  $\mathrm{crash} \leftarrow
  (\texttt{exit\_code} \neq 0)$
  \Comment{structured output}
\State \textcolor{knife}{\textsc{Destroy}}:\;
  $\mathcal{C}.\texttt{kill}()$;\;\;
  reclaim all resources
  \Comment{\textcolor{knife}{no persistent state}}
\Statex
\Ensure $(\mathrm{result},\;
  t_{\mathrm{run}},\;
  \texttt{exit\_code},\;
  \texttt{stdout},\;
  \texttt{stderr})$
  for \cref{alg:code-eval}, lines~6--7
\end{algorithmic}
\end{algorithm}

\begin{remark}[Sandbox $=$ MuJoCo]
\label{rem:sandbox-mujoco}
\Cref{alg:sandbox} is MuJoCo for code.
The isomorphism is line-by-line:
\begin{center}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{@{}lll@{}}
\toprule
& \textbf{Locomotion (MuJoCo)} &
\textbf{Code (sandbox)} \\
\midrule
\textsc{Build}
  & load XML model
  & create container \\
\textsc{Inject}
  & apply joint torques
  & write code to filesystem \\
\textsc{Execute}
  & step physics ($\Delta t$)
  & run program ($t_{\max}$) \\
\textsc{Extract}
  & read sensors
  & read stdout, exit code, timing \\
\textsc{Destroy}
  & reset simulation
  & kill container \\
\midrule
\textcolor{knife}{Isolation}
  & joint limits, ground plane
  & no network, read-only fs \\
\textcolor{knife}{Gravity}
  & $9.81\;\mathrm{m/s^2}$
  & time limit $t_{\max}$ \\
\textcolor{knife}{Ground contact}
  & collision detection
  & memory limit $m_{\max}$ \\
\textcolor{knife}{$c_{\max}$}
  & joint torque bound
  & syscall whitelist $\mathcal{S}$ \\
\bottomrule
\end{tabular}
\end{center}
A robot cannot fly through the floor.
Code cannot escape the sandbox.
The physics is different.
The \textcolor{knife}{knife} is the same.
\end{remark}

\begin{remark}[Sinking bound: 地面不能变成水]
\label{rem:sinking-bound}
MuJoCo uses a \emph{soft contact} model: the ground exerts a
spring-damper force $F = k\,\delta + b\,\dot\delta$ proportional
to penetration depth $\delta$.
For small $\delta$ (a few millimetres), this approximation is
accurate.
For large $\delta$, the model breaks: forces explode,
bodies tunnel through the ground plane, and the simulation
becomes physically meaningless.

In the viability geometry (\cref{sec:viab-geom}), the ground
plane is $\partial K$---the boundary of the viability kernel.
The viability metric $g_V = V^{-2}\,g_S$
(\cref{def:viab-metric}) has a \emph{pole} at $V = 0$:
the boundary is at infinite $g_V$-distance, and
\cref{prop:viab-complete} guarantees that no trajectory can
reach it in finite time.
This completeness theorem \emph{requires} that the boundary be
a hard wall.

A soft-contact spring is not a wall---it is a \emph{resource}
that stores and releases energy.
It can be depleted (penetrated past its valid range).
If the ground becomes soft, $\partial K$ is no longer a
constraint that holds; it becomes a medium that yields.
\textcolor{water}{The ground becomes water.}

The sinking bound prevents this:
\[
  z_{\mathrm{contact}}(t)
  \;\geq\;
  z_{\min}
  \quad\text{for all contact points, all } t.
\]
This is not an optimisation heuristic.
It is the \emph{categorical distinction} between $\partial K$
(constraint, infinite barrier, pole of $g_V$) and $V$
(resource, depletable, conformal factor).
The ground is not water.
地面不能变成水.

It is the \emph{robot's} viability obligation to not break the
contact physics of its own simulator.
The sinking bound is not a limitation of MuJoCo that the
engineer works around---it is a constraint the robot must
actively maintain, just as the king must maintain the
institutional structure he governs through
(\cref{thm:paradox}).
The robot lives inside the physics model; breaking it is
breaking~$\partial K$ itself.

In the isomorphism of \cref{rem:sandbox-mujoco}: the code
sandbox's memory limit $m_{\max}$ plays the same role.
If a program consumes memory beyond $m_{\max}$, the OS's
virtual memory subsystem enters pathological behaviour
(thrashing, OOM killer).
The memory limit is the ground plane for code.
\end{remark}

\begin{remark}[Bill of materials: what you actually need]
\label{rem:bill-of-materials}
\Cref{alg:finetune,alg:code-eval,alg:sandbox} are
mechanically executable.
Every step maps to a shell command or library call.
The complete bill of materials:
\begin{center}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Resource} & \textbf{Example} & \textbf{Cost} &
\textbf{Algorithm} \\
\midrule
GPU server
  & RunPod\,/\,Lambda\,/\,vast.ai
  & \textcolor{caution}{\$1/hr} (A100)
  & \cref{alg:finetune} \\
Checkpoint
  & \texttt{deepseek-coder-v2}
  & \textcolor{water}{free} (HuggingFace)
  & \cref{alg:finetune}, line~1 \\
LoRA library
  & \texttt{peft}
  & \textcolor{water}{free} (pip)
  & \cref{alg:finetune}, line~2 \\
Sandbox
  & Docker\,/\,\texttt{nsjail}
  & \textcolor{water}{free}
  & \cref{alg:sandbox} \\
Judge API key
  & Gemini-Pro
  & \textcolor{water}{free} (60 req/min)
  & \cref{alg:code-eval}, line~11 \\
Compiler
  & \texttt{gcc}\,/\,\texttt{nvcc}\,/\,\texttt{rustc}
  & \textcolor{water}{free}
  & \cref{alg:code-eval}, line~2 \\
Profiler
  & \texttt{time}\,/\,\texttt{perf}\,/\,\texttt{nsight}
  & \textcolor{water}{free}
  & \cref{alg:code-eval}, line~13 \\
Task data
  & $(z, x^*)$ pairs or spec $z$
  & \textcolor{caution}{user-provided}
  & \cref{alg:finetune}, line~5 \\
\bottomrule
\end{tabular}
\end{center}
Six of eight inputs are \textcolor{water}{free}.
The two that cost money:
a GPU server (\textcolor{caution}{\$1/hr})
and your task data.
Everything else---checkpoint, LoRA library, sandbox, judge,
compiler, profiler---is open-source or free-tier.

The automation boundary is sharp.
An AI coding assistant (e.g.\ Claude Code) with SSH access to the
GPU server can execute \cref{alg:finetune} end-to-end:
install dependencies, download the checkpoint, write the training
script, launch the four-phase curriculum, call the sandbox
(\cref{alg:sandbox}), call the judge (\cref{alg:code-eval}),
merge the adapter, and upload the result.
The human provides \textcolor{caution}{two things}:
the GPU server and the task specification.
The \textcolor{water}{pipeline} does the rest.
\end{remark}

\begin{definition}[Instruction set]
\label{def:instruction-set}
The \emph{instruction set} of the agentic calculus is
\[
  \mathcal{I}
  \;=\;
  \bigl\{\,
    \textcolor{water}{\sigma},\;\;
    \textcolor{water}{\circ},\;\;
    \textcolor{sword}{\varphi}
  \,\bigr\}
  \;=\;
  \{\sigma,\, \circ,\, \varphi\}
  \;\setminus\;
  \{\textcolor{knife}{\partial}\}.
\]
A program $p$ on the execution graph $G$ is a finite sequence of
instructions drawn from~$\mathcal{I}$.
The \textsc{Cut} operation $\textcolor{knife}{\partial}$ is
\emph{not} an instruction: it is a constraint imposed by the
environment (the knife), not an action taken by the agent.
\end{definition}

\begin{remark}[The knife cannot cut itself]
\label{rem:knife-self}
The exclusion of $\textcolor{knife}{\partial}$ from~$\mathcal{I}$
is not a design choice.
It is forced.

A program $p \in \mathcal{I}^*$ can
\textcolor{water}{slide} (transport data),
\textcolor{water}{compose} (chain operations), and
\textcolor{sword}{change phase} (switch regime).
It \emph{cannot} cut its own capacity.
Code cannot remove its own weight-decay.
A function cannot delete its own regulariser.
The knife is not a tool the agent wields---it is the boundary the
agent lives inside.

Suppose it could.
Let $p_{\partial}$ be a program that sets $\gamma(e) = 0$ on its
own edges.
By \cref{thm:camus}, setting $\gamma \to 0$ eliminates the
stability margin $\lambda_1 > 0$ (\cref{rem:contact-stability}).
The system becomes unstable: small perturbations amplify.
The program that removes its own knife
\textcolor{knife}{destroys itself}.

This is the diagonal constraint.
Every computable instruction set has exactly one operation it cannot
apply to itself:
\begin{center}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{System} & \textbf{Instruction set} &
\textbf{Excluded operation} \\
\midrule
Turing machine & $\{$read, write, move, halt$\}$ &
  halt on self \\
$\lambda$-calculus & $\{$abstract, apply$\}$ &
  decide own termination \\
Agentic calculus & $\{\sigma, \circ, \varphi\}$ &
  $\partial$ on self \\
\bottomrule
\end{tabular}
\end{center}
The consequence is the same in all three cases:
\\[4pt]
\hspace*{2em}%
\textcolor{knife}{You cannot use the system to prove the system
safe.}
\\[4pt]
The \textcolor{knife}{knife} is the price of
\textcolor{water}{flow}.
Remove it, and the flow destroys the channel.
\end{remark}

\begin{definition}[Sandbox daemon]
\label{def:sandbox-daemon}
The \emph{sandbox daemon} is a persistent instance of
\cref{alg:sandbox} that separates the one-time
\textcolor{sword}{\textsc{Build}} and
\textcolor{knife}{\textsc{Destroy}} from the per-evaluation
loop:
\[
  \underbrace{%
    \textcolor{sword}{\textsc{Build}}
  }_{\text{once}}
  \;\to\;
  \underbrace{%
    \bigl(\,
      \textcolor{water}{\textsc{Inject}} \;\to\;
      \textcolor{water}{\textsc{Execute}} \;\to\;
      \textcolor{water}{\textsc{Extract}}
    \,\bigr)^N
  }_{\text{per evaluation}}
  \;\to\;
  \underbrace{%
    \textcolor{knife}{\textsc{Destroy}}
  }_{\text{once}}.
\]
The container $\mathcal{C}$ persists across all $N$ evaluations
in \cref{alg:finetune}.
The compilation cache, GPU context, and sanitiser hooks survive
between calls.
\end{definition}

\begin{remark}[The daemon is the standing structure]
\label{rem:daemon-standing}
In locomotion (\cref{alg:loco}), the robot body persists across
all rollouts.
You do not rebuild the quadruped every step.
The standing structure (\cref{rem:standing})---joints, torques,
contact modes---is loaded once and reused.

The sandbox daemon is the same pattern.
The four engineering requirements for CUDA trajectory optimisation
map to the four tower layers:
\begin{center}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Gap} & \textbf{Tower} & \textbf{Daemon component} &
\textbf{Persistence} \\
\midrule
Host-device wrapper
  & \textcolor{water}{力${}^*$}
  & \texttt{cudaMalloc}, grid config, launch
  & GPU context survives \\
Compilation bottleneck
  & \textcolor{sword}{立${}^*$}
  & \texttt{ccache}, hot \texttt{nvcc} daemon
  & only recompile $\Delta$ \\
Mathematical oracle
  & \textcolor{caution}{丽(正)${}^*$}
  & KKT residual $< \varepsilon$,
    constraint violation $< \delta$
  & validator loaded once \\
GPU isolation
  & \textcolor{knife}{刀}
  & \texttt{--gpus all}, \texttt{compute-sanitizer}
  & container $\mathcal{C}$ persists \\
\bottomrule
\end{tabular}
\end{center}
Without the daemon, \cref{alg:sandbox} creates and destroys a
container per evaluation.
With the daemon, the container is the body.
\textsc{Build} is birth.
\textsc{Destroy} is death.
The training loop runs \emph{inside} a life.

The isomorphism is exact:
\begin{center}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{@{}lll@{}}
\toprule
& \textbf{Locomotion} & \textbf{CUDA sandbox daemon} \\
\midrule
Body & quadruped (MuJoCo) & container $\mathcal{C}$ (Docker) \\
Standing & $h > h_{\min}$ & \texttt{nvcc} cache warm \\
Joint limits & $c(e) \leq c_{\max}$ &
  \texttt{compute-sanitizer}: 0 errors \\
Rollout & simulate $\to$ reward & inject $\to$ compile $\to$ run \\
Persistence & body across rollouts & $\mathcal{C}$ across evaluations \\
\bottomrule
\end{tabular}
\end{center}
You do not rebuild the robot every step.
You do not rebuild the sandbox every evaluation.
The daemon \emph{is} the standing structure for code.
\end{remark}
